{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8cf18e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "from torch.nn import functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bb6a6e",
   "metadata": {},
   "source": [
    "### Masked Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5d39b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lock 2181257613128 acquired on C:\\Users\\ky_moon/.cache\\huggingface\\transformers\\45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7263f96485642dcba353db458ed5ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lock 2181257613128 released on C:\\Users\\ky_moon/.cache\\huggingface\\transformers\\45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Lock 2181781889224 acquired on C:\\Users\\ky_moon/.cache\\huggingface\\transformers\\c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b385853c3614258a9431613fb0e0a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lock 2181781889224 released on C:\\Users\\ky_moon/.cache\\huggingface\\transformers\\c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Lock 2182501681032 acquired on C:\\Users\\ky_moon/.cache\\huggingface\\transformers\\534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7e627f29a9461f9d3933db44e8b455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lock 2182501681032 released on C:\\Users\\ky_moon/.cache\\huggingface\\transformers\\534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Lock 2181662919112 acquired on C:\\Users\\ky_moon/.cache\\huggingface\\transformers\\3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b556b85904774b9a9050694fa6b83943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lock 2181662919112 released on C:\\Users\\ky_moon/.cache\\huggingface\\transformers\\3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Lock 2182502664328 acquired on C:\\Users\\ky_moon/.cache\\huggingface\\transformers\\a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc85183dd6a4bf6aa37faef1c65ffef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lock 2182502664328 released on C:\\Users\\ky_moon/.cache\\huggingface\\transformers\\a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') \n",
    "# 사전 학습된 BERT 모델 불러오기 (case sensitive하지 않음)\n",
    "# WordPiece 임베딩 기반\n",
    "\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased', return_dict = True) \n",
    "# downstream task 관련 클래스\n",
    "# MLM 모델, dic결과 return (어떤 단어를 masking 했는지)\n",
    "\n",
    "text = \"The capital of France, \" + tokenizer.mask_token + \", contains the Eiffel Tower.\"\n",
    "# [mask]=Paris\n",
    "\n",
    "input = tokenizer.encode_plus(text, return_tensors = \"pt\")\n",
    "# 텍스트의 다양한 특징을 추출\n",
    "# pt - pythorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc463ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text : The capital of France, [MASK], contains the Eiffel Tower.\n",
      "[mask] : [MASK]\n",
      "input : {'input_ids': tensor([[  101,  1996,  3007,  1997,  2605,  1010,   103,  1010,  3397,  1996,\n",
      "          1041, 13355,  2884,  3578,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "print('text :', text)\n",
    "print('[mask] :', tokenizer.mask_token)\n",
    "print('input :', input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4265f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_index = torch.where(input[\"input_ids\"][0] == tokenizer.mask_token_id)\n",
    "# 어떤 단어가 마스킹 되었는지 인덱스를 찾음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a5678ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  101,  1996,  3007,  1997,  2605,  1010,   103,  1010,  3397,  1996,\n",
      "         1041, 13355,  2884,  3578,  1012,   102])\n",
      "103\n",
      "(tensor([6]),)\n"
     ]
    }
   ],
   "source": [
    "print(input['input_ids'][0])\n",
    "print(tokenizer.mask_token_id)\n",
    "print(mask_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f59911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(**input)  # 모델의 결과값\n",
    "logits = output.logits  # 마스킹된 단어가 치환될 단어들의 확률 분포\n",
    "softmax = F.softmax(logits, dim=-1)  # 소프트맥스 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b5f4730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France, paris, contains the Eiffel Tower.\n",
      "The capital of France, lyon, contains the Eiffel Tower.\n",
      "The capital of France, lille, contains the Eiffel Tower.\n",
      "The capital of France, toulouse, contains the Eiffel Tower.\n",
      "The capital of France, marseille, contains the Eiffel Tower.\n",
      "The capital of France, orleans, contains the Eiffel Tower.\n",
      "The capital of France, strasbourg, contains the Eiffel Tower.\n",
      "The capital of France, nice, contains the Eiffel Tower.\n",
      "The capital of France, cannes, contains the Eiffel Tower.\n",
      "The capital of France, versailles, contains the Eiffel Tower.\n"
     ]
    }
   ],
   "source": [
    "mask_word = softmax[0, mask_index, :]\n",
    "top_10 = torch.topk(mask_word, 10, dim = 1)[1][0]  # 소프트맥스에서의 상위 10개\n",
    "for token in top_10:\n",
    "   word = tokenizer.decode([token])\n",
    "   new_sentence = text.replace(tokenizer.mask_token, word)\n",
    "   print(new_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef032eb3",
   "metadata": {},
   "source": [
    "### Next Sentence Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2471b546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForNextSentencePrediction: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9953, 0.0047]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased') # NSP 모델\n",
    "\n",
    "prompt = \"The child came home from school.\"\n",
    "next_sentence = \"He played soccer after school.\"\n",
    "encoding = tokenizer.encode_plus(prompt, next_sentence, return_tensors='pt')\n",
    "\n",
    "outputs = model(**encoding)[0]\n",
    "softmax = F.softmax(outputs, dim = 1)\n",
    "print(softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e3dc6e",
   "metadata": {},
   "source": [
    "### Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5bc0b99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertForSequenceClassification\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "import os\n",
    "from kobert_transformers import get_kobert_model\n",
    "\n",
    "class PYBERTClassifier(nn.Module):\n",
    "    '''\n",
    "     Customized BERT Sequence Model\n",
    "    '''\n",
    "    def __init__(self, n_classes, model_name):\n",
    "        #PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
    "        super(PYBERTClassifier, self).__init__()\n",
    "        if 'etri' in model_name or 'mecab' in model_name:\n",
    "            self.bert = BertModel.from_pretrained(os.path.abspath('pytorch_model.bin'),\n",
    "                                  output_hidden_states = False)\n",
    "        else:\n",
    "            self.bert = BertModel.from_pretrained(model_name)  # BERT 모델 불러오기\n",
    "\n",
    "        #print(self.bert.config.hidden_size)\n",
    "\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.bert(\n",
    "            input_ids=input_ids,  # tokenization이후 token id들의 리스트\n",
    "            attention_mask=attention_mask  # \n",
    "        )\n",
    "        #print(pooled_output.shape)\n",
    "\n",
    "        output = self.drop(pooled_output)\n",
    "        return self.out(output)\n",
    "\n",
    "    def name(self):\n",
    "        return 'PYBERTClassifier'\n",
    "\n",
    "class PYBERTClassifierGenAtten(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_classes,\n",
    "                 model_name,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "\n",
    "        '''\n",
    "        bert,\n",
    "                 hidden_size=768,\n",
    "                 num_classes=2,\n",
    "                 dr_rate=None,\n",
    "                 params=None\n",
    "        '''\n",
    "\n",
    "        super(PYBERTClassifierGenAtten, self).__init__()\n",
    "        if 'etri' in model_name or 'mecab' in model_name:\n",
    "            self.bert = BertModel.from_pretrained(os.path.abspath('pytorch_model.bin'),\n",
    "                                                  output_hidden_states=False)\n",
    "        else:\n",
    "            self.bert = BertModel.from_pretrained(model_name)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "        self.dr_rate = dr_rate\n",
    "        self.attention_mask=None\n",
    "\n",
    "        if self.dr_rate != None:\n",
    "            print('dropout ' + str(self.dr_rate))\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "\n",
    "    def gen_attention_mask(self, token_ids, targets):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(targets):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def get_attention_mask(self, atten_mask):\n",
    "        self.attention_mask = atten_mask\n",
    "\n",
    "    def forward(self, token_ids, targets, segment_ids, attention_mask):\n",
    "        if attention_mask is None:\n",
    "            self.attention_mask = self.gen_attention_mask(token_ids, targets)\n",
    "        else:\n",
    "            self.attention_mask = attention_mask\n",
    "\n",
    "        _, pooler = self.bert(input_ids=token_ids,\n",
    "                              token_type_ids=segment_ids.long(),\n",
    "                              attention_mask=self.attention_mask.float().to(token_ids.device))\n",
    "\n",
    "        if self.dr_rate:\n",
    "            output = self.dropout(pooler)\n",
    "\n",
    "        return self.out(output)\n",
    "\n",
    "    def name(self):\n",
    "        return 'PYBERTClassifierGenAtten'\n",
    "\n",
    "class PYBertForSequenceClassification:\n",
    "    '''\n",
    "        Use pytorch's BERTForSeqeunceClassification\n",
    "        Bert Model transformer with a sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for GLUE tasks.\n",
    "        labels (torch.LongTensor of shape (batch_size,), optional, defaults to None)\n",
    "        – Labels for computing the sequence classification/regression loss. Indices should be in [0, ..., config.num_labels - 1]. If config.num_labels == 1 a regression loss is computed (Mean-Square loss),\n",
    "        If config.num_labels > 1 a classification loss is computed (Cross-Entropy).\n",
    "    '''\n",
    "    def __init__(self, n_classes, model_name):\n",
    "        self.model = BertForSequenceClassification.from_pretrained(  # 감성 분류 용\n",
    "                                    model_name,  # Use the 12-layer BERT model, with an uncased vocab.\n",
    "                                    num_labels=n_classes,  # The number of output labels--2 for binary classification.\n",
    "                                    # You can increase this for multi-class tasks.\n",
    "                                    output_attentions=False,  # Whether the model returns attentions weights.\n",
    "                                    output_hidden_states=False,  # Whether the model returns all hidden-states.\n",
    "                                )\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(device)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.model\n",
    "\n",
    "    def name(self):\n",
    "        return 'PYBertForSequenceClassification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d066350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForMaskedLM, BertModel, DistilBertForMaskedLM, DistilBertModel\n",
    "\n",
    "\n",
    "def get_kobert_model():\n",
    "    \"\"\" Return BertModel for Kobert \"\"\"\n",
    "    model = BertModel.from_pretrained(\"monologg/kobert\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_kobert_lm():\n",
    "    \"\"\" Return BertForMaskedLM for Kobert \"\"\"\n",
    "    model = BertForMaskedLM.from_pretrained(\"monologg/kobert-lm\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_distilkobert_model():\n",
    "    \"\"\" Return DistilBertModel for DistilKobert \"\"\"\n",
    "    model = DistilBertModel.from_pretrained(\"monologg/distilkobert\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_distilkobert_lm():\n",
    "    \"\"\" Return DistilBertForMaskedLM for DistilKobert \"\"\"\n",
    "    model = DistilBertForMaskedLM.from_pretrained(\"monologg/distilkobert\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb984f8",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec6b67a",
   "metadata": {},
   "source": [
    "input 데이터가 특정한 형식으로 입력되어야 함. 다음과 같은 형식들이 필요.\n",
    "\n",
    "* [CLS]\n",
    "* [SEP]\n",
    "* Tokens : BERT 모델의 vocabulary에 존재하는 토큰 리스트\n",
    "* Token IDs : BERT Tokenizer에서 나오는 토큰에 대한 정수 아이디\n",
    "* Mask IDs : 토큰 시퀀스 중 어떤 요소가 문장에 존재하는 토큰이고 어떤 것이 padding element인지 나타내는 아이디\n",
    "* Segment IDs : 문장 식별 아이디\n",
    "* Positional Embeddings : 시퀀스 내에서 토큰의 위치를 표현\n",
    "\n",
    "Transformer의 tokenizer.encode_plus함수가 위의 7개 정보를 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7538e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "from load_kobert_model import get_kobert_model\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "from scipy.spatial.distance import cosine\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import pytorch_pretrained_bert as ppb\n",
    "import torch\n",
    "\n",
    "#bert multi-lingual model\n",
    "#https://github.com/google-research/bert/blob/master/multilingual.md\n",
    "\n",
    "def get_pretrained_model(pretrained_type):\n",
    "    if pretrained_type == 'etri':\n",
    "        # use etri tokenizer\n",
    "        print('not supported')\n",
    "    elif pretrained_type == 'skt':\n",
    "        # use gluonnlp tokenizer\n",
    "        import gluonnlp as nlp\n",
    "        vocab_path = './pretrained_model/skt/vocab.json'\n",
    "        tokenizer_path = './pretrained_model/skt/tokenizer.model'\n",
    "        vocab = nlp.vocab.BERTVocab.from_json(open(vocab_path, 'rt').read())\n",
    "        tokenizer = nlp.data.BERTSPTokenizer(\n",
    "            path=tokenizer_path, vocab=vocab, lower=False)\n",
    "        vocab = tokenizer.vocab.token_to_idx\n",
    "    elif pretrained_type == 'kobert':\n",
    "        from tokenization_kobert import KoBertTokenizer\n",
    "        tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')\n",
    "\n",
    "    else:\n",
    "        TypeError('Invalid pretrained model type')\n",
    "    return tokenizer\n",
    "\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "tokenizer = get_pretrained_model('kobert') # 한국어 전용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "85f0446d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '▁오늘', '은', '▁하루', '종', '일', '▁비가', '▁', '와', '서', '▁날씨', '가', '▁흐', '리', '고', '▁바람', '이', '▁많이', '▁불', '었습니다', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "text = \"오늘은 하루종일 비가 와서 날씨가 흐리고 바람이 많이 불었습니다\"\n",
    "\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"  # special token\n",
    "\n",
    "# Tokenize our sentence with the BERT tokenizer.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Print out the tokens.\n",
    "print (tokenized_text) \n",
    "\n",
    "# WordPiece 임베딩을 사용하기 때문에 subwords, 글자 단위로 쪼개짐\n",
    "# vocabulary에 존재하지 않는 단어들은 OOV또는 UNK 심볼로 처리되지 않고 subword나 낱글자로 쪼개져서 토큰화됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c8cc9673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]             2\n",
      "▁오늘           3,419\n",
      "은             7,086\n",
      "▁하루           4,937\n",
      "종             7,268\n",
      "일             7,126\n",
      "▁비가           2,515\n",
      "▁               517\n",
      "와             6,983\n",
      "서             6,553\n",
      "▁날씨           1,408\n",
      "가             5,330\n",
      "▁흐            5,196\n",
      "리             6,122\n",
      "고             5,439\n",
      "▁바람           2,195\n",
      "이             7,096\n",
      "▁많이           1,956\n",
      "▁불            2,485\n",
      "었습니다          6,890\n",
      "[SEP]             3\n"
     ]
    }
   ],
   "source": [
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)  # 토큰들을 vocabulary 인덱스로 매핑\n",
    "\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a6fe7085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "segments_ids = [1] * len(tokenized_text)\n",
    "\n",
    "print(segments_ids)  # 하나의 문장이라 모두 1로 표현됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dd3b6a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2, 3419, 7086, 4937, 7268, 7126, 2515,  517, 6983, 6553, 1408, 5330,\n",
      "         5196, 6122, 5439, 2195, 7096, 1956, 2485, 6890,    3]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# 토큰화된 데이터를 torch tensors 구조로 변환\n",
    "\n",
    "tokens_tensor = torch.tensor([indexed_tokens]) \n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "print(tokens_tensor)\n",
    "print(segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2937257d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased',  # 인터넷으로부터 사전 학습된 모델을 가져옴\n",
    "                                  output_hidden_states = True, # 모든 hidden state의 정보를 return\n",
    "                                  )\n",
    "model.eval()  # 평가 모드로 호출(학습이 끝난 후), 학습시 사용되는 dropout, regularization실행 x\n",
    "\n",
    "# bert base uncased는 12개의 layer로 구성된 DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "085d5ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "    \n",
    "# torch.no_grad’는 PyTorch에게 텍스트에 BERT모델을 적용하는 forward pass동안 완벽한 네트워크를 만들지 않도록 지도 하는데 사용함 \n",
    "# 메모리 소비를 줄이고 속도 향상을 위해서\n",
    "\n",
    "# Evaluating the model will return a different number of objects based on \n",
    "# how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "# becase we set `output_hidden_states = True`, the third item will be the \n",
    "# hidden states from all layers. See the documentation for more details:\n",
    "# https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "\n",
    "hidden_states = outputs[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b2f1aa5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.1922, -0.6141, -0.4304,  ..., -0.0455, -0.2215,  0.3119],\n",
       "          [ 0.0957, -0.5905, -0.4006,  ..., -0.0442, -0.0114,  0.3972],\n",
       "          [ 0.3319,  0.5648, -0.4425,  ..., -0.1601,  0.9972, -1.3536],\n",
       "          ...,\n",
       "          [ 0.0883, -0.2967,  0.1458,  ..., -0.4173,  0.3155,  0.0045],\n",
       "          [ 0.9272, -0.3361, -0.4502,  ..., -0.4800, -1.1224,  0.0485],\n",
       "          [ 0.2557, -0.3528, -0.6428,  ...,  0.1651, -0.2962,  0.0377]]]),\n",
       " tensor([[[ 0.2560, -0.2960, -0.0824,  ...,  0.0641, -0.0085,  0.3444],\n",
       "          [ 0.0902, -1.0775, -0.2841,  ...,  0.0472,  0.2717,  0.2524],\n",
       "          [ 1.0793,  0.2208, -0.4960,  ..., -0.0100,  1.1624, -1.3039],\n",
       "          ...,\n",
       "          [ 0.2286, -0.4662,  0.6871,  ..., -0.7888,  0.6660,  0.1339],\n",
       "          [ 1.1085, -0.6479, -0.3018,  ..., -0.5112, -1.0376, -0.2699],\n",
       "          [ 0.3558, -0.3359, -0.0091,  ...,  0.3476,  0.0627, -0.1449]]]),\n",
       " tensor([[[ 0.1217, -0.4286,  0.0262,  ...,  0.1283,  0.0588,  0.2211],\n",
       "          [-0.1001, -1.1888, -0.5378,  ...,  0.1180,  0.1015,  0.4223],\n",
       "          [ 1.2808,  0.1362, -0.7214,  ..., -0.0830,  1.7863, -1.6300],\n",
       "          ...,\n",
       "          [ 0.2005, -0.5438,  0.9825,  ..., -0.4661,  0.7215, -0.0320],\n",
       "          [ 1.5428, -0.7757, -0.7032,  ..., -0.2624, -1.0350, -0.4383],\n",
       "          [ 0.3003, -0.2277,  0.4086,  ...,  0.6161,  0.0141, -0.0850]]]),\n",
       " tensor([[[ 0.1253, -0.2263, -0.0691,  ..., -0.0925,  0.0985,  0.2895],\n",
       "          [-0.0720, -0.6756, -0.0720,  ...,  0.0278, -0.0923,  0.3889],\n",
       "          [ 0.6943,  0.2865, -0.5900,  ..., -0.1454,  1.3490, -1.6161],\n",
       "          ...,\n",
       "          [ 0.4073,  0.0351,  0.5912,  ..., -0.5174,  0.1458, -0.5947],\n",
       "          [ 2.0447, -0.6789, -0.4609,  ..., -0.1544, -1.3489, -0.6543],\n",
       "          [ 0.1976, -0.1839,  0.6556,  ...,  0.5507, -0.0503, -0.2493]]]),\n",
       " tensor([[[ 0.2708, -0.6287, -0.3283,  ..., -0.0513,  0.3233,  0.5185],\n",
       "          [-0.0631, -0.6953,  0.0366,  ...,  0.2891, -0.3142,  0.2637],\n",
       "          [ 0.2647, -0.0095,  0.0580,  ...,  1.0429,  1.1948, -1.1379],\n",
       "          ...,\n",
       "          [ 0.5692, -0.2742,  0.9390,  ..., -0.2880, -0.0983, -0.7778],\n",
       "          [ 2.1955, -1.0730, -0.6631,  ...,  0.5245, -1.7479, -0.8445],\n",
       "          [ 0.3748, -0.6503,  0.9793,  ...,  0.9260, -0.2627, -0.3192]]]),\n",
       " tensor([[[ 0.0289, -0.5113, -0.3083,  ..., -0.0498,  0.4622,  0.5939],\n",
       "          [ 0.0192, -0.5919,  0.0687,  ...,  0.5445, -0.1191,  0.5412],\n",
       "          [ 0.1918,  0.5923,  0.0543,  ...,  0.9127,  0.8508, -0.1696],\n",
       "          ...,\n",
       "          [ 0.5019,  0.2344,  0.6691,  ...,  0.3614, -0.0072, -0.4510],\n",
       "          [ 1.9489, -0.5305,  0.2800,  ...,  0.9758, -1.4298, -0.4989],\n",
       "          [ 0.5414, -0.1240,  1.0938,  ...,  1.0026,  0.2346, -0.1104]]]),\n",
       " tensor([[[ 0.4362, -0.3046, -0.0458,  ..., -1.4278,  0.5928,  0.2525],\n",
       "          [ 0.2565, -0.4486,  0.4952,  ...,  0.2958, -0.1183,  0.2368],\n",
       "          [ 0.6204,  0.6424,  0.1367,  ..., -0.2808,  0.4261,  0.0166],\n",
       "          ...,\n",
       "          [ 1.0023,  0.2852,  1.0493,  ..., -1.3276,  0.1145, -0.3891],\n",
       "          [ 1.9715, -0.2339,  0.6481,  ..., -0.1039, -0.5628, -0.5891],\n",
       "          [ 0.7117,  0.3560,  1.1861,  ..., -0.2528,  0.3276, -0.4112]]]),\n",
       " tensor([[[ 0.1675, -0.1344,  0.0756,  ..., -0.3769,  0.3898,  0.2403],\n",
       "          [-0.0445, -0.1848,  0.5441,  ...,  0.7377, -0.3887,  0.2059],\n",
       "          [ 0.5979,  0.7948,  0.2369,  ...,  0.1804, -0.2636,  0.4546],\n",
       "          ...,\n",
       "          [ 0.7356,  0.5204,  1.2027,  ..., -0.5079, -0.2275, -0.0715],\n",
       "          [ 1.3462, -0.0638,  0.2871,  ...,  0.7290, -0.6974, -0.3860],\n",
       "          [ 0.6203,  0.5877,  0.6898,  ...,  0.3756, -0.1512, -0.2052]]]),\n",
       " tensor([[[-0.1365, -0.0787,  0.3156,  ..., -0.3160,  0.2753,  0.1622],\n",
       "          [-0.2994, -0.1271,  0.5704,  ...,  0.5412, -0.0038,  0.3542],\n",
       "          [-0.1045,  0.9185,  0.5734,  ...,  0.2870,  0.0199,  0.7888],\n",
       "          ...,\n",
       "          [ 0.2408,  0.5184,  1.3179,  ..., -0.4087,  0.0362, -0.1658],\n",
       "          [ 0.8906,  0.0639,  0.7244,  ...,  0.6220, -0.3860, -0.4024],\n",
       "          [ 0.4252,  0.9318,  1.0945,  ...,  0.5025,  0.0302, -0.0900]]]),\n",
       " tensor([[[-0.1229,  0.0287,  0.2481,  ..., -0.4792, -0.1246,  0.3842],\n",
       "          [-0.1296,  0.1183,  0.4455,  ...,  0.1521, -0.0959,  0.4745],\n",
       "          [ 0.0014,  1.0306,  0.3564,  ..., -0.3349, -0.2401,  0.8549],\n",
       "          ...,\n",
       "          [ 0.1968,  0.6720,  1.1531,  ..., -0.6462, -0.1636,  0.2098],\n",
       "          [ 0.6841,  0.0384,  0.4989,  ...,  0.2805, -0.4354, -0.0374],\n",
       "          [ 0.2795,  0.7348,  1.0324,  ..., -0.0509, -0.1185,  0.2194]]]),\n",
       " tensor([[[-0.2045, -0.1046,  0.1788,  ..., -0.5771, -0.3200,  0.5607],\n",
       "          [-0.1267,  0.2669,  0.4128,  ..., -0.1363, -0.3876,  0.6367],\n",
       "          [-0.1047,  0.9488,  0.3049,  ..., -0.3115, -0.6217,  0.9717],\n",
       "          ...,\n",
       "          [ 0.0244,  0.5293,  0.7977,  ..., -0.7845, -0.2971,  0.3906],\n",
       "          [ 0.4258, -0.0896,  0.2995,  ..., -0.0728, -0.5686,  0.1828],\n",
       "          [ 0.0176,  0.4874,  0.6628,  ..., -0.2455, -0.2931,  0.2505]]]),\n",
       " tensor([[[-0.3954, -0.2603, -0.3725,  ..., -0.8776, -0.2680,  0.5825],\n",
       "          [-0.4085,  0.1705, -0.1905,  ..., -0.4325, -0.4283,  0.8793],\n",
       "          [-0.4178,  0.6950, -0.2508,  ..., -0.4491, -0.4935,  1.1879],\n",
       "          ...,\n",
       "          [-0.3090,  0.2249,  0.1158,  ..., -0.8751, -0.3091,  0.4754],\n",
       "          [ 0.0421, -0.2191, -0.2718,  ..., -0.3002, -0.4284,  0.3275],\n",
       "          [-0.4428,  0.1477, -0.0159,  ..., -0.5494, -0.2728,  0.4822]]]),\n",
       " tensor([[[ 0.0903,  0.0797, -0.0295,  ..., -0.2743,  0.1018,  0.2465],\n",
       "          [ 0.0410,  0.1645,  0.0732,  ..., -0.2130,  0.0986,  0.3509],\n",
       "          [-0.0249,  0.2729,  0.0102,  ..., -0.1414,  0.1326,  0.4433],\n",
       "          ...,\n",
       "          [ 0.0772,  0.1798,  0.1632,  ..., -0.3579,  0.1158,  0.1678],\n",
       "          [ 0.2200,  0.1037,  0.0249,  ..., -0.1380,  0.0635,  0.1310],\n",
       "          [ 0.0663,  0.1641,  0.0899,  ..., -0.1804,  0.1151,  0.1874]]]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c128045e",
   "metadata": {},
   "source": [
    "hidden_states에 저장된 정보는\n",
    "\n",
    "* layer 수 : 13 (12개의 layer + word embedding layer)\n",
    "* batch 수 : 1 (1문장)\n",
    "* 단어/토큰 수 : 22 (예제 문장)\n",
    "* Hidden unit의 수 : 768 (hidden embedding 차원, 자질의 수)\n",
    "\n",
    "한 문장을 표현하기 위해 13*22*768=219648개의 고유한 값들이 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e664f9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
      "Number of batches: 1\n",
      "Number of tokens: 21\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cd663bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of hidden_states:  <class 'tuple'>\n",
      "Tensor shape for each layer:  torch.Size([1, 21, 768])\n"
     ]
    }
   ],
   "source": [
    "# `hidden_states` is a Python list.\n",
    "print('Type of hidden_states: ', type(hidden_states))\n",
    "\n",
    "# Each layer in the list is a torch tensor.\n",
    "print('Tensor shape for each layer: ', hidden_states[0].size()) # 하나의 문장에 22개의 단어가 존재하고, 각 단어는 768개의 차원으로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3a49cd6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 1, 21, 768])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = torch.stack(hidden_states, dim=0)  # 모든 layer를 하나의 큰 tensor로 합침\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3cfdcfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 21, 768])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)  # batch 차원은 필요 없어서 삭제 (1문장 밖에 없음)\n",
    "token_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dee7dced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 13, 768])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = token_embeddings.permute(1, 0, 2)  # layer, token의 위치를 변경\n",
    "token_embeddings.size()\n",
    "\n",
    "# 각 토큰은 13개의 768의 길이를 갖는 분리된 벡터들을 가짐\n",
    "# 개별 단어를 만들기 위해서는 layer벡터 중 몇 개를 합치거나 하나만 선택 -> 어떤 layer를 선택할지, 어떤 layer들을 합쳐야할 지 결정해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "549bcb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 21 x 3072\n"
     ]
    }
   ],
   "source": [
    "# 방법1. 마지막 4개 layer를 concatenate (권장)\n",
    "\n",
    "# Stores the token vectors, with shape [22 x 3,072 (4 x 768)]\n",
    "token_vecs_cat = []\n",
    "for token in token_embeddings:\n",
    "    # `token` is a [12 x 768] tensor\n",
    "    # Concatenate the vectors (that is, append them together) from the last four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ed20a8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 21 x 768\n"
     ]
    }
   ],
   "source": [
    "# 방법2. 마지막 4개 layer를 summing\n",
    "\n",
    "token_vecs_sum = []\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[-4:], dim=0)\n",
    "    \n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ccc750fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence Vectors 만들기\n",
    "\n",
    "token_vecs = hidden_states[-2][0]  # 각 토큰당 두 번째 부터 마지막 까지의 layer들의 평균\n",
    "\n",
    "# Calculate the average of all 22 token vectors.\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d966606c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our final sentence embedding vector of shape: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size())  # 768 길이의 벡터 -> 문장들의 유사도를 계산할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ba068530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS]\n",
      "1 ▁오늘\n",
      "2 은\n",
      "3 ▁하루\n",
      "4 종\n",
      "5 일\n",
      "6 ▁비가\n",
      "7 ▁\n",
      "8 와\n",
      "9 서\n",
      "10 ▁날씨\n",
      "11 가\n",
      "12 ▁흐\n",
      "13 리\n",
      "14 고\n",
      "15 ▁바람\n",
      "16 이\n",
      "17 ▁많이\n",
      "18 ▁불\n",
      "19 었습니다\n",
      "20 [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i, token_str in enumerate(tokenized_text):\n",
    "    print (i, token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "09871727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 vector values for each instance of \"bank\".\n",
      "\n",
      "bank vault    tensor([-0.5759, -0.3973,  1.3785,  0.7051, -0.9139])\n",
      "bank robber   tensor([-0.0816,  2.6933,  0.4515,  2.2942, -2.6820])\n",
      "river bank    tensor([ 1.3720, -0.1666,  0.5515, -0.2751, -1.7715])\n"
     ]
    }
   ],
   "source": [
    "print('First 5 vector values for each instance of \"bank\".')\n",
    "print('')\n",
    "print(\"bank vault   \", str(token_vecs_sum[6][:5]))\n",
    "print(\"bank robber  \", str(token_vecs_sum[10][:5]))\n",
    "print(\"river bank   \", str(token_vecs_sum[19][:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4363575c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector similarity for  *similar*  meanings:  0.84\n",
      "Vector similarity for *different* meanings:  0.78\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "diff_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[19])\n",
    "same_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[6])\n",
    "\n",
    "print('Vector similarity for  *similar*  meanings:  %.2f' % same_bank)\n",
    "print('Vector similarity for *different* meanings:  %.2f' % diff_bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dd0797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
