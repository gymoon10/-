{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "monologg_train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjCuxCET6dzC",
        "outputId": "7f8fe2c4-1c2d-4a68-f616-7c3ae77948e5"
      },
      "source": [
        "!git clone https://github.com/monologg/KoBERT-NER.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'KoBERT-NER'...\n",
            "remote: Enumerating objects: 145, done.\u001b[K\n",
            "remote: Counting objects: 100% (145/145), done.\u001b[K\n",
            "remote: Compressing objects: 100% (103/103), done.\u001b[K\n",
            "remote: Total 145 (delta 82), reused 97 (delta 38), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (145/145), 17.54 MiB | 16.19 MiB/s, done.\n",
            "Resolving deltas: 100% (82/82), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7mtbfTq6g6j",
        "outputId": "50677c12-0807-42c3-b491-9acca4e49029"
      },
      "source": [
        "# 저장소로 이동\n",
        "%cd KoBERT-NER"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/KoBERT-NER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0n9Dg4p7pxP"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bofmd74p6u0x"
      },
      "source": [
        "import argparse\n",
        "\n",
        "from trainer import Trainer\n",
        "from utils import init_logger, load_tokenizer, set_seed, MODEL_CLASSES, MODEL_PATH_MAP\n",
        "from data_loader import load_and_cache_examples"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSVdXls0jJF1"
      },
      "source": [
        "! python3 main.py --model_type kobert --do_train --do_eval --write_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik0n04e3sDZj"
      },
      "source": [
        "![image](https://user-images.githubusercontent.com/44194558/139646095-fe66465e-6e6b-4ab3-aa9a-bb457a57d9ee.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gQyQ3067tcf",
        "outputId": "fc44cd52-24e3-4138-f0db-71ddd71bddc1"
      },
      "source": [
        "! python3 predict.py --input_file {'/content/KoBERT-NER/sample_pred_in.txt'} --output_file {'/content/KoBERT-NER/sample_pred_out.txt'} --model_dir {'/content/KoBERT-NER/model'}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/01/2021 09:36:39 - INFO - transformers.configuration_utils -   loading configuration file ./model/config.json\n",
            "11/01/2021 09:36:39 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForTokenClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": \"naver-ner\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"UNK\",\n",
            "    \"1\": \"O\",\n",
            "    \"2\": \"PER-B\",\n",
            "    \"3\": \"PER-I\",\n",
            "    \"4\": \"FLD-B\",\n",
            "    \"5\": \"FLD-I\",\n",
            "    \"6\": \"AFW-B\",\n",
            "    \"7\": \"AFW-I\",\n",
            "    \"8\": \"ORG-B\",\n",
            "    \"9\": \"ORG-I\",\n",
            "    \"10\": \"LOC-B\",\n",
            "    \"11\": \"LOC-I\",\n",
            "    \"12\": \"CVL-B\",\n",
            "    \"13\": \"CVL-I\",\n",
            "    \"14\": \"DAT-B\",\n",
            "    \"15\": \"DAT-I\",\n",
            "    \"16\": \"TIM-B\",\n",
            "    \"17\": \"TIM-I\",\n",
            "    \"18\": \"NUM-B\",\n",
            "    \"19\": \"NUM-I\",\n",
            "    \"20\": \"EVT-B\",\n",
            "    \"21\": \"EVT-I\",\n",
            "    \"22\": \"ANM-B\",\n",
            "    \"23\": \"ANM-I\",\n",
            "    \"24\": \"PLT-B\",\n",
            "    \"25\": \"PLT-I\",\n",
            "    \"26\": \"MAT-B\",\n",
            "    \"27\": \"MAT-I\",\n",
            "    \"28\": \"TRM-B\",\n",
            "    \"29\": \"TRM-I\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"AFW-B\": 6,\n",
            "    \"AFW-I\": 7,\n",
            "    \"ANM-B\": 22,\n",
            "    \"ANM-I\": 23,\n",
            "    \"CVL-B\": 12,\n",
            "    \"CVL-I\": 13,\n",
            "    \"DAT-B\": 14,\n",
            "    \"DAT-I\": 15,\n",
            "    \"EVT-B\": 20,\n",
            "    \"EVT-I\": 21,\n",
            "    \"FLD-B\": 4,\n",
            "    \"FLD-I\": 5,\n",
            "    \"LOC-B\": 10,\n",
            "    \"LOC-I\": 11,\n",
            "    \"MAT-B\": 26,\n",
            "    \"MAT-I\": 27,\n",
            "    \"NUM-B\": 18,\n",
            "    \"NUM-I\": 19,\n",
            "    \"O\": 1,\n",
            "    \"ORG-B\": 8,\n",
            "    \"ORG-I\": 9,\n",
            "    \"PER-B\": 2,\n",
            "    \"PER-I\": 3,\n",
            "    \"PLT-B\": 24,\n",
            "    \"PLT-I\": 25,\n",
            "    \"TIM-B\": 16,\n",
            "    \"TIM-I\": 17,\n",
            "    \"TRM-B\": 28,\n",
            "    \"TRM-I\": 29,\n",
            "    \"UNK\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 8002\n",
            "}\n",
            "\n",
            "11/01/2021 09:36:39 - INFO - transformers.modeling_utils -   loading weights file ./model/pytorch_model.bin\n",
            "11/01/2021 09:36:43 - INFO - __main__ -   ***** Model Loaded *****\n",
            "11/01/2021 09:36:43 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, data_dir='./data', do_eval=True, do_train=True, eval_batch_size=64, gradient_accumulation_steps=1, label_file='label.txt', learning_rate=5e-05, logging_steps=1000, max_grad_norm=1.0, max_seq_len=50, max_steps=-1, model_dir='./model', model_name_or_path='monologg/kobert', model_type='kobert', no_cuda=False, num_train_epochs=20.0, pred_dir='./preds', save_steps=1000, seed=42, task='naver-ner', test_file='test.tsv', train_batch_size=32, train_file='train.tsv', warmup_steps=0, weight_decay=0.0, write_pred=True)\n",
            "11/01/2021 09:36:44 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model from cache at /root/.cache/torch/transformers/1f871cf1d80a4c09742b5f2094cc7ab9163dfbcfb930d99fdc9149aebf6a13bb.7555cd8e0e341a4d19f33dcb20eaf8614c72f56827d1b28481046caabba18eb3\n",
            "11/01/2021 09:36:44 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt from cache at /root/.cache/torch/transformers/c247d0225676d99ae7f3e6d39dba68b77756181415828f922c6393e4aecb53ce.5d8505da4be274704344000e8d9a798ff03b513f5053f98f7e97d719a9a9891b\n",
            "Predicting: 100% 1/1 [00:00<00:00, 65.86it/s]\n",
            "11/01/2021 09:36:44 - INFO - __main__ -   Prediction Done!\n"
          ]
        }
      ]
    }
  ]
}