{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_Bert_CRF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgIf4N0Jq5sb",
        "outputId": "1730a61c-5dce-49cf-e387-f92a0bb178dc"
      },
      "source": [
        "!git clone https://github.com/eagle705/pytorch-bert-crf-ner.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-bert-crf-ner'...\n",
            "remote: Enumerating objects: 1725, done.\u001b[K\n",
            "remote: Counting objects: 100% (1725/1725), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1636/1636), done.\u001b[K\n",
            "remote: Total 1725 (delta 118), reused 1662 (delta 71), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1725/1725), 27.16 MiB | 23.31 MiB/s, done.\n",
            "Resolving deltas: 100% (118/118), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vtf81JBTzfji",
        "outputId": "dcddc619-2b5d-40ad-e30c-4879d737999e"
      },
      "source": [
        "# 저장소로 이동\n",
        "%cd pytorch-bert-crf-ner"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pytorch-bert-crf-ner\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXixAYOzfvC5"
      },
      "source": [
        "# !pip install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiJiE9IuFsq2"
      },
      "source": [
        "!pip install pytorch-crf \n",
        "!pip install pytorch-transformers==1.2.0\n",
        "!pip install transformers==2.1.1  # https://github.com/SKTBrain/KoBERT/issues/31\n",
        "!pip install torch==1.8.1\n",
        "!pip install torchvision==0.9.1\n",
        "!pip install gluonnlp\n",
        "!pip install mxnet==1.8.0.post0\n",
        "!pip install konlpy==0.5.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgE9tMPXrR05"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import argparse\n",
        "import numpy as np\n",
        "import logging\n",
        "import random\n",
        "import pickle\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "from pytorch_transformers import AdamW, WarmupLinearSchedule\n",
        "from torch.utils.tensorboard import SummaryWriter # from tensorboardX import SummaryWriter\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn, optim\n",
        "from tqdm import tqdm, trange\n",
        "from data_utils.utils import CheckpointManager, SummaryManager\n",
        "from model.net import KobertCRF\n",
        "from model.utils import Config\n",
        "\n",
        "from data_utils.ner_dataset import NamedEntityRecognitionDataset, NamedEntityRecognitionFormatter\n",
        "from data_utils.vocab_tokenizer import Vocabulary, Tokenizer\n",
        "from data_utils.pad_sequence import keras_pad_fn\n",
        "from gluonnlp.data import SentencepieceTokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
        "from kobert.utils import get_tokenizer\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32ISnuKk3Wy-"
      },
      "source": [
        "## Vocabulary & Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn4065dr1Ggs",
        "outputId": "55fbe417-ba8b-4544-a674-4f2c76c8eb14"
      },
      "source": [
        "# 데이터 & 모델 불러오기\n",
        "data_dir = Path('data_in')\n",
        "model_dir = Path('experiments/base_model_with_crf_val')\n",
        "model_config = Config(json_path=model_dir / 'config.json')\n",
        "\n",
        "# Tokenizer & Vocab 불러오기\n",
        "tok_path = get_tokenizer() # 'https://kobert.blob.core.windows.net/models/kobert/tokenizer/tokenizer_78b3253a26.model' url에서 다운로드\n",
        "ptr_tokenizer = SentencepieceTokenizer(tok_path)\n",
        "\n",
        "_, vocab_of_gluonnlp = get_pytorch_kobert_model()  # KoBERT 모델의 vocab 불러오기\n",
        "token_to_idx = vocab_of_gluonnlp.token_to_idx\n",
        "\n",
        "model_config.vocab_size = len(token_to_idx)\n",
        "vocab = Vocabulary(token_to_idx=token_to_idx)\n",
        "\n",
        "print(\"len(token_to_idx): \", len(token_to_idx))\n",
        "with open(model_dir / \"token2idx_vocab.json\", 'w', encoding='utf-8') as f:\n",
        "    json.dump(token_to_idx, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "# experiments/base_model_with_crf_val 경로에 Vocab & Tokenizer 저장\n",
        "with open(model_dir / \"vocab.pkl\", 'wb') as f:\n",
        "    pickle.dump(vocab, f)\n",
        "\n",
        "# experiments/base_model_with_crf_val 경로에서 Vocab & Tokenizer 로드\n",
        "with open(model_dir / \"vocab.pkl\", 'rb') as f:\n",
        "    vocab = pickle.load(f)\n",
        "\n",
        "# Tokenizer, NER Formatter\n",
        "tokenizer = Tokenizer(vocab=vocab, split_fn=ptr_tokenizer, pad_fn=keras_pad_fn, maxlen=model_config.maxlen)\n",
        "ner_formatter = NamedEntityRecognitionFormatter(vocab=vocab, tokenizer=tokenizer, maxlen=model_config.maxlen, model_dir=model_dir)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model\n",
            "using cached model\n",
            "using cached model\n",
            "len(token_to_idx):  8002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUzyysmYABUR",
        "outputId": "06cffeff-9a62-4254-8bb9-be7b692ae6b4"
      },
      "source": [
        "# NER Formatter\n",
        "text = \"첫 회를 시작으로 13일까지 4일간 총 4회에 걸쳐 매 회 2편씩 총 8편이 공개될 예정이다.\"\n",
        "label_text = \"첫 회를 시작으로 <13일:DAT>까지 <4일간:DUR> 총 <4회:NOH>에 걸쳐 매 회 <2편:NOH>씩 총 <8편:NOH>이 공개될 예정이다.\"\n",
        "\n",
        "token_ids_with_cls_sep, tokens, prefix_sum_of_token_start_index = ner_formatter.transform_source_fn(text)\n",
        "\n",
        "print('token_ids_with_cls_sep :', token_ids_with_cls_sep)\n",
        "print()\n",
        "print('tokens :', tokens)  # 문자 단위로 토큰화\n",
        "print()\n",
        "print('prefix_sum_of_token_start_index :', prefix_sum_of_token_start_index)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token_ids_with_cls_sep : [[   2 4481  517 7955 2988  541 7128  605 7127 4512  605 7953 6896  894\n",
            "  1986 5152  553 7720 6792 4512  624 7720 7096 1026 5902 3414   54    3\n",
            "     1    1]]\n",
            "\n",
            "tokens : ['▁첫', '▁', '회를', '▁시작으로', '▁13', '일까지', '▁4', '일간', '▁총', '▁4', '회', '에', '▁걸쳐', '▁매', '▁회', '▁2', '편', '씩', '▁총', '▁8', '편', '이', '▁공개', '될', '▁예정이다', '.']\n",
            "\n",
            "prefix_sum_of_token_start_index : [0, 1, 2, 4, 9, 12, 15, 17, 19, 21, 23, 24, 25, 28, 30, 32, 34, 35, 36, 38, 40, 41, 42, 45, 46, 51]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thks6AFW3sQk"
      },
      "source": [
        "## Train & Val Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Tz7yGJv1fxz",
        "outputId": "b2cad03d-5d7a-4725-a20f-9618a77b5144"
      },
      "source": [
        "cwd = Path.cwd()\n",
        "data_in = cwd / \"data_in\"\n",
        "\n",
        "# pytorch dataloader 형식으로 전환\n",
        "train_data_dir = data_in / \"NER-master\" / \"말뭉치 - 형태소_개체명\"\n",
        "tr_ds = NamedEntityRecognitionDataset(train_data_dir=train_data_dir, model_dir=model_dir)\n",
        "tr_ds.set_transform_fn(transform_source_fn=ner_formatter.transform_source_fn, transform_target_fn=ner_formatter.transform_target_fn)\n",
        "tr_dl = DataLoader(tr_ds, batch_size=model_config.batch_size, shuffle=True, num_workers=4, drop_last=False)\n",
        "\n",
        "val_data_dir = data_in / \"NER-master\" / \"validation_set\"\n",
        "val_ds = NamedEntityRecognitionDataset(train_data_dir=val_data_dir, model_dir=model_dir)\n",
        "val_ds.set_transform_fn(transform_source_fn=ner_formatter.transform_source_fn, transform_target_fn=ner_formatter.transform_target_fn)\n",
        "val_dl = DataLoader(val_ds, batch_size=model_config.batch_size, shuffle=True, num_workers=4, drop_last=False)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num of files:  1425\n",
            "num of files:  2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-dsHiqJ4C2h"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-ASK7CsPOGt"
      },
      "source": [
        "# 사전 학습된 KoBERT 모델 불러오기\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model = KobertCRF(config=model_config, num_classes=len(tr_ds.ner_to_index))\n",
        "model.to(device)\n",
        "model.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsmBzrfSDPZy"
      },
      "source": [
        "![image](https://user-images.githubusercontent.com/44194558/139571178-364c4669-8207-48d9-874a-5ec78b775f3e.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbzK77Oh4IIW"
      },
      "source": [
        "## Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRX4Ets837og",
        "outputId": "db667ddb-3ede-4eaf-a181-a46eec1cf688"
      },
      "source": [
        "train_examples_len = len(tr_ds)\n",
        "val_examples_len = len(val_ds)\n",
        "print(\"num of train: {}, num of val: {}\".format(train_examples_len, val_examples_len))\n",
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
        "\n",
        "# num_train_optimization_steps = int(train_examples_len / model_config.batch_size / model_config.gradient_accumulation_steps) * model_config.epochs\n",
        "t_total = len(tr_dl) // model_config.gradient_accumulation_steps * model_config.epochs\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=model_config.learning_rate, eps=model_config.adam_epsilon)\n",
        "scheduler = WarmupLinearSchedule(optimizer, warmup_steps=model_config.warmup_steps, t_total=t_total)\n",
        "\n",
        "n_gpu = torch.cuda.device_count()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num of train: 23032, num of val: 931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKz6DCOe5_HW"
      },
      "source": [
        "## Train & Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vV4sCtvJ4K1j"
      },
      "source": [
        "# save\n",
        "tb_writer = SummaryWriter('{}/runs'.format(model_dir))\n",
        "checkpoint_manager = CheckpointManager(model_dir)\n",
        "summary_manager = SummaryManager(model_dir)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc1bOwgj4VC7"
      },
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "logger.info(\"***** Running training *****\")\n",
        "logger.info(\"  Num examples = %d\", len(tr_ds))\n",
        "logger.info(\"  Num Epochs = %d\", model_config.epochs)\n",
        "logger.info(\"  Instantaneous batch size per GPU = %d\", model_config.batch_size)\n",
        "logger.info(\"  Gradient Accumulation steps = %d\", model_config.gradient_accumulation_steps)\n",
        "logger.info(\"  Total optimization steps = %d\", t_total)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnp7OacJ4dL-"
      },
      "source": [
        "global_step = 0\n",
        "tr_loss, logging_loss = 0.0, 0.0\n",
        "best_dev_acc, best_dev_loss = 0.0, 99999999999.0\n",
        "best_steps = 0\n",
        "model.zero_grad()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJTVdZmS4h-o"
      },
      "source": [
        "def set_seed(seed=100):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "    if n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed() "
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEfjY1fE5xFh"
      },
      "source": [
        "def evaluate(model, val_dl, prefix=\"NER\"):\n",
        "    \"\"\" evaluate accuracy and return result \"\"\"\n",
        "    results = {}\n",
        "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "    # Eval!\n",
        "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    list_of_y_real = []\n",
        "    list_of_pred_tags = []\n",
        "    count_correct = 0\n",
        "    total_count = 0\n",
        "\n",
        "    for batch in tqdm(val_dl, desc=\"Evaluating\"):\n",
        "        model.train()\n",
        "        x_input, token_type_ids, y_real = map(lambda elm: elm.to(device), batch)\n",
        "        with torch.no_grad():\n",
        "            inputs = {'input_ids': x_input,\n",
        "                      'token_type_ids': token_type_ids,\n",
        "                      'tags': y_real}\n",
        "            log_likelihood, sequence_of_tags = model(**inputs)\n",
        "\n",
        "            eval_loss += -1 * log_likelihood.float().item()\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "        y_real = y_real.to('cpu')\n",
        "        sequence_of_tags = torch.tensor(sequence_of_tags).to('cpu')\n",
        "        count_correct += (sequence_of_tags == y_real).float()[y_real != 2].sum()  # 0,1,2,3 -> [CLS], [SEP], [PAD], [MASK] index\n",
        "        total_count += len(y_real[y_real != 2])\n",
        "\n",
        "        for seq_elm in y_real.tolist():\n",
        "            list_of_y_real += seq_elm\n",
        "\n",
        "        for seq_elm in sequence_of_tags.tolist():\n",
        "            list_of_pred_tags += seq_elm\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    acc = (count_correct / total_count).item()  # tensor -> float\n",
        "    result = {\"eval_acc\": acc, \"eval_loss\": eval_loss}\n",
        "    results.update(result)\n",
        "\n",
        "    return results, list_of_y_real, list_of_pred_tags"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4jPf_U46x_4"
      },
      "source": [
        "import operator\n",
        "import pandas as pd\n",
        "def save_cr_and_cm(val_dl, list_of_y_real, list_of_pred_tags, cr_save_path=\"classification_report.csv\", cm_save_path=\"confusion_matrix.png\"):\n",
        "    \"\"\" print classification report and confusion matrix \"\"\"\n",
        "\n",
        "    # target_names = val_dl.dataset.ner_to_index.keys()\n",
        "    sorted_ner_to_index = sorted(val_dl.dataset.ner_to_index.items(), key=operator.itemgetter(1))\n",
        "    target_names = []\n",
        "    for ner_tag, index in sorted_ner_to_index:\n",
        "        if ner_tag in ['[CLS]', '[SEP]', '[PAD]', '[MASK]', 'O']:\n",
        "            continue\n",
        "        else:\n",
        "            target_names.append(ner_tag)\n",
        "\n",
        "    label_index_to_print = list(range(5, 25))  # ner label indice except '[CLS]', '[SEP]', '[PAD]', '[MASK]' and 'O' tag\n",
        "    print(classification_report(y_true=list_of_y_real, y_pred=list_of_pred_tags, target_names=target_names, labels=label_index_to_print, digits=4))\n",
        "    cr_dict = classification_report(y_true=list_of_y_real, y_pred=list_of_pred_tags, target_names=target_names, labels=label_index_to_print, digits=4, output_dict=True)\n",
        "    df = pd.DataFrame(cr_dict).transpose()\n",
        "    df.to_csv(cr_save_path)\n",
        "    np.set_printoptions(precision=2)\n",
        "    plot_confusion_matrix(y_true=list_of_y_real, y_pred=list_of_pred_tags, classes=target_names, labels=label_index_to_print, normalize=False, title='Confusion matrix, without normalization')\n",
        "    plt.savefig(cm_save_path)\n",
        "    # plt.show()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "def plot_confusion_matrix(y_true, y_pred, classes, labels,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=labels)\n",
        "    # Only use the labels that appear in the data\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    # --- plot 크기 조절 --- #\n",
        "    plt.rcParams['savefig.dpi'] = 200\n",
        "    plt.rcParams['figure.dpi'] = 200\n",
        "    plt.rcParams['figure.figsize'] = [20, 20]  # plot 크기\n",
        "    plt.rcParams.update({'font.size': 10})\n",
        "    # --- plot 크기 조절 --- #\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "\n",
        "    # --- bar 크기 조절 --- #\n",
        "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    plt.colorbar(im, cax=cax)\n",
        "    # --- bar 크기 조절 --- #\n",
        "    # ax.figure.colorbar(im, ax=ax)\n",
        "\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVcZ5JkMDu7t"
      },
      "source": [
        "#### Train & Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoyYZKNPPSF0"
      },
      "source": [
        "train_iterator = trange(int(model_config.epochs), desc=\"Epoch\")\n",
        "for _epoch, _ in enumerate(train_iterator):\n",
        "    epoch_iterator = tqdm(tr_dl, desc=\"Iteration\")\n",
        "    epoch = _epoch\n",
        "    for step, batch in enumerate(epoch_iterator):\n",
        "        model.train()\n",
        "        x_input, token_type_ids, y_real = map(lambda elm: elm.to(device), batch)\n",
        "        log_likelihood, sequence_of_tags = model(x_input, token_type_ids, y_real)\n",
        "\n",
        "        # loss: negative log-likelihood\n",
        "        loss = -1 * log_likelihood\n",
        "\n",
        "        if n_gpu > 1:\n",
        "            loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
        "        if model_config.gradient_accumulation_steps > 1:\n",
        "            loss = loss / model_config.gradient_accumulation_steps\n",
        "\n",
        "        loss.backward()  # 역전파 수행\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), model_config.max_grad_norm)\n",
        "        tr_loss += loss.item()  # 훈련 손실 계산\n",
        "\n",
        "        if (step + 1) % model_config.gradient_accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            scheduler.step()  # Update learning rate schedule\n",
        "            model.zero_grad()\n",
        "            global_step += 1\n",
        "            \n",
        "            # 훈련 성능 검증 단계\n",
        "            with torch.no_grad(): \n",
        "                sequence_of_tags = torch.tensor(sequence_of_tags).to(device)\n",
        "                mb_acc = (sequence_of_tags == y_real).float()[y_real != vocab.PAD_ID].mean()  # 훈련 정확도 계산\n",
        "\n",
        "            tr_acc = mb_acc.item()  # 훈련 정확도\n",
        "            tr_loss_avg = tr_loss / global_step  # 훈련 손실 평균\n",
        "            tr_summary = {'loss': tr_loss_avg, 'acc': tr_acc}\n",
        "\n",
        "            # if step % 50 == 0:\n",
        "            print('epoch : {}, global_step : {}, tr_loss: {:.3f}, tr_acc: {:.2%}'.format(epoch + 1, global_step, tr_summary['loss'], tr_summary['acc']))\n",
        "\n",
        "            # training & evaluation log\n",
        "            if model_config.logging_steps > 0 and global_step % model_config.logging_steps == 0:\n",
        "                if model_config.evaluate_during_training:  # Only evaluate when single GPU otherwise metrics may not average well\n",
        "                    # 검증 데이터셋 이용\n",
        "                    eval_summary, list_of_y_real, list_of_pred_tags = evaluate(model, val_dl)  \n",
        "                    tb_writer.add_scalar('lr', scheduler.get_lr()[0], global_step)\n",
        "                    tb_writer.add_scalars('loss', {'train': (tr_loss - logging_loss) / model_config.logging_steps, 'val': eval_summary[\"eval_loss\"]}, global_step)\n",
        "                    tb_writer.add_scalars('acc', {'train': tr_acc, 'val': eval_summary[\"eval_acc\"]}, global_step)\n",
        "                    print(\"eval acc: {}, loss: {}, global steps: {}\".format(eval_summary['eval_acc'], eval_summary['eval_loss'], global_step))\n",
        "                print(\"Average loss: {} at global step: {}\".format((tr_loss - logging_loss) / model_config.logging_steps, global_step))\n",
        "                logging_loss = tr_loss\n",
        "\n",
        "            # save model\n",
        "            if model_config.save_steps > 0 and global_step % model_config.save_steps == 0:\n",
        "                eval_summary, list_of_y_real, list_of_pred_tags = evaluate(model, val_dl)\n",
        "\n",
        "                # Save model checkpoint\n",
        "                output_dir = os.path.join(model_config.output_dir, 'epoch-{}'.format(epoch + 1))\n",
        "                if not os.path.exists(output_dir):\n",
        "                    os.makedirs(output_dir)\n",
        "                print(\"Saving model checkpoint to %s\", output_dir)\n",
        "                state = {'global_step': global_step + 1,\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                        'opt_state_dict': optimizer.state_dict()}\n",
        "                summary = {'train': tr_summary, 'eval': eval_summary}\n",
        "                summary_manager.update(summary)\n",
        "                print(\"summary: \", summary)\n",
        "                summary_manager.save('summary.json')\n",
        "\n",
        "                # Save\n",
        "                is_best = eval_summary[\"eval_acc\"] >= best_dev_acc  # acc 기준 \n",
        "                if is_best:\n",
        "                    best_dev_acc = eval_summary[\"eval_acc\"]\n",
        "                    best_dev_loss = eval_summary[\"eval_loss\"]\n",
        "                    best_steps = global_step\n",
        "                    # if args.do_test:\n",
        "                    # results_test = evaluate(model, test_dl, test=True)\n",
        "                    # for key, value in results_test.items():\n",
        "                    #     tb_writer.add_scalar('test_{}'.format(key), value, global_step)\n",
        "                    # logger.info(\"test acc: %s, loss: %s, global steps: %s\", str(eval_summary['eval_acc']), str(eval_summary['eval_loss']), str(global_step))\n",
        "\n",
        "                    checkpoint_manager.save_checkpoint(state, 'best-epoch-{}-step-{}-acc-{:.3f}.bin'.format(epoch + 1, global_step, best_dev_acc))\n",
        "                    print(\"Saving model checkpoint as best-epoch-{}-step-{}-acc-{:.3f}.bin\".format(epoch + 1, global_step, best_dev_acc))\n",
        "\n",
        "                    # print classification report and save confusion matrix\n",
        "                    cr_save_path = model_dir / 'best-epoch-{}-step-{}-acc-{:.3f}-cr.csv'.format(epoch + 1, global_step, best_dev_acc)\n",
        "                    cm_save_path = model_dir / 'best-epoch-{}-step-{}-acc-{:.3f}-cm.png'.format(epoch + 1, global_step, best_dev_acc)\n",
        "                    save_cr_and_cm(val_dl, list_of_y_real, list_of_pred_tags, cr_save_path=cr_save_path, cm_save_path=cm_save_path)\n",
        "                else:\n",
        "                    torch.save(state, os.path.join(output_dir, 'model-epoch-{}-step-{}-acc-{:.3f}.bin'.format(epoch + 1, global_step, eval_summary[\"eval_acc\"])))\n",
        "                    print(\"Saving model checkpoint as model-epoch-{}-step-{}-acc-{:.3f}.bin\".format(epoch + 1, global_step, eval_summary[\"eval_acc\"]))\n",
        "\n",
        "tb_writer.close()\n",
        "print(\"global_step = {}, average loss = {}\".format(global_step, tr_loss / global_step))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mk9i6TFHnD7"
      },
      "source": [
        "**훈련&검증 정확도 및 손실**\n",
        "\n",
        "<br/>\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/44194558/139571833-e2f29f2b-16ba-4db4-9791-665a8128fcfc.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUcwBUYYIdUv"
      },
      "source": [
        "**예측 결과(confution matrix)**\n",
        "\n",
        "<br/>\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/44194558/139571944-eee865d9-9123-42ca-8e5a-f8f3a0630004.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDffpIhNQaID"
      },
      "source": [
        "**성능 요약**\n",
        "\n",
        "<br/>\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/44194558/139573063-03e05cb6-b633-4e9b-b53f-144d1851e97d.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxw2qr4Ra-fj"
      },
      "source": [
        "학습 완료된 모델은 base_model_with_crf_val에 .bin 형식으로 저장됨. (inference시 사용)\n",
        "\n",
        "<br/>\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/44194558/139574183-818a3fb1-71a6-414c-89e1-86ce95cdc2e1.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "789E9OMWoHz8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}