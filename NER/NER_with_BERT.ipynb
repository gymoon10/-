{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER with BERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a9d3262a8d1843dcaae43048afa6f6d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7bc67a4bed4c4ea19bf2f124e6be5a71",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2962d3225e5a40aeb0af90d9d9e74e9a",
              "IPY_MODEL_09ca27f4e21e4dbf80df7aa84fc427f3",
              "IPY_MODEL_7ee559cf84a84816894734750592c5c6"
            ]
          }
        },
        "7bc67a4bed4c4ea19bf2f124e6be5a71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2962d3225e5a40aeb0af90d9d9e74e9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e1045196b1a34403b19829858dfd55b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3002bc0e6aa439f9800571ed7f7be9e"
          }
        },
        "09ca27f4e21e4dbf80df7aa84fc427f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5da66e8ec03b49608477fcc91d2d857b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3815be4fa92d4a318f8a82657994ba4d"
          }
        },
        "7ee559cf84a84816894734750592c5c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b0e782bd3e04422d8e856fcc86cdb4d6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 10.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d44e7f4a4906465c832753f238fd8ded"
          }
        },
        "e1045196b1a34403b19829858dfd55b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3002bc0e6aa439f9800571ed7f7be9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5da66e8ec03b49608477fcc91d2d857b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3815be4fa92d4a318f8a82657994ba4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b0e782bd3e04422d8e856fcc86cdb4d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d44e7f4a4906465c832753f238fd8ded": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a00596b23ae4017b85c887d1dff6265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6436fed6071d4cc6be0f1f0b82dacf2b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_721720b737a24c909ae3847880aba245",
              "IPY_MODEL_8d697e1468bb40e1ba5c295ddefb72f9",
              "IPY_MODEL_98222a40bf4c47e389ed6647bf47addc"
            ]
          }
        },
        "6436fed6071d4cc6be0f1f0b82dacf2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "721720b737a24c909ae3847880aba245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5adff03fa897475c8cf4654196ba2566",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f7452b91815480d866e62cd33d5dd45"
          }
        },
        "8d697e1468bb40e1ba5c295ddefb72f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_39576bda35e84108ad0f19a5da12a6f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e95151e73dd5400bba2ddc988938d86c"
          }
        },
        "98222a40bf4c47e389ed6647bf47addc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e8756282296d49a5b4eb9a275c10feb1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:09&lt;00:00, 39.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bbadb27a7404452481a0ffed99b61001"
          }
        },
        "5adff03fa897475c8cf4654196ba2566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f7452b91815480d866e62cd33d5dd45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "39576bda35e84108ad0f19a5da12a6f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e95151e73dd5400bba2ddc988938d86c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8756282296d49a5b4eb9a275c10feb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bbadb27a7404452481a0ffed99b61001": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdVLXeBc0Opk",
        "outputId": "0b7e4253-cc18-4cb0-8b1b-7d4145c352e4"
      },
      "source": [
        "!pip install keras==2.3.1\n",
        "!pip install torch==1.1.0\n",
        "!pip install transformers==2.5.1\n",
        "!pip install seqeval"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras==2.3.1\n",
            "  Downloading Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 26.1 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20 kB 18.4 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████                          | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 81 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 266 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 317 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 368 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 377 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (3.13)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▌                         | 10 kB 46.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20 kB 50.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 30 kB 58.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 40 kB 62.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 50 kB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from keras==2.3.1) (1.1.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.3.1) (1.5.2)\n",
            "Installing collected packages: keras-applications, keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.6.0\n",
            "    Uninstalling keras-2.6.0:\n",
            "      Successfully uninstalled keras-2.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.6.0 requires keras~=2.6, but you have keras 2.3.1 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-2.3.1 keras-applications-1.0.8\n",
            "Collecting torch==1.1.0\n",
            "  Downloading torch-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (676.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 676.9 MB 3.9 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.1.0) (1.19.5)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu111\n",
            "    Uninstalling torch-1.9.0+cu111:\n",
            "      Successfully uninstalled torch-1.9.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.10.0+cu111 requires torch==1.9.0, but you have torch 1.1.0 which is incompatible.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.1.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.1.0\n",
            "Collecting transformers==2.5.1\n",
            "  Downloading transformers-2.5.1-py3-none-any.whl (499 kB)\n",
            "\u001b[K     |████████████████████████████████| 499 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.18.64-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 67.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (4.62.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 57.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (3.3.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 31.4 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "  Downloading tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 19.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (2.23.0)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.7 MB/s \n",
            "\u001b[?25hCollecting botocore<1.22.0,>=1.21.64\n",
            "  Downloading botocore-1.21.64-py3-none-any.whl (8.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0 MB 51.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.64->boto3->transformers==2.5.1) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 74.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.64->boto3->transformers==2.5.1) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (2021.5.30)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 72.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (7.1.2)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, tokenizers, sentencepiece, sacremoses, boto3, transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.18.64 botocore-1.21.64 jmespath-0.10.0 s3transfer-0.5.0 sacremoses-0.0.46 sentencepiece-0.1.96 tokenizers-0.5.2 transformers-2.5.1 urllib3-1.25.11\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=c5df7ffac1d6fd82203f420f9be79a81ce9109cb35df38520d0be0584a97ca0e\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dnyzV_h0cb5"
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "from seqeval.metrics import f1_score\n",
        "from seqeval.metrics import classification_report,accuracy_score,f1_score\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5B1KgRg0ceK"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm,trange\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "from transformers import BertForTokenClassification, AdamW"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0J6wf5f0e4J",
        "outputId": "a10b82af-2a1a-463a-887f-35a7947b6ac2"
      },
      "source": [
        "!pip list | grep -E 'transformers|torch|Keras'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras                         2.3.1\n",
            "Keras-Applications            1.0.8\n",
            "Keras-Preprocessing           1.1.2\n",
            "torch                         1.1.0\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.10.0\n",
            "torchvision                   0.10.0+cu111\n",
            "transformers                  2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHB1drm23KGZ"
      },
      "source": [
        "## 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNfDrJBf0mxJ",
        "outputId": "e88e1932-d1bd-4526-90b8-2aaec97251a0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x69ezvHY2HIN"
      },
      "source": [
        "data_path = \"/content/drive/My Drive/ner_dataset.csv\"\n",
        "df_data = pd.read_csv(data_path, sep=\",\", encoding=\"latin1\").fillna(method='ffill')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYW72XFG2_Q5"
      },
      "source": [
        "ner_dataset.csv\n",
        "\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/44194558/137710745-2c2888e0-7d77-47fb-bd35-df90c956c74f.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idzpSjGq2Z8w",
        "outputId": "d0a6c768-1281-49e5-c872-859de763545b"
      },
      "source": [
        "df_data.columns"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Sentence #', 'Word', 'POS', 'Tag'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "KKpcSxId2dRv",
        "outputId": "5a893726-ee4f-4348-dc48-3dd35e1a7f79"
      },
      "source": [
        "df_data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1  Sentence: 1             of   IN   O\n",
              "2  Sentence: 1  demonstrators  NNS   O\n",
              "3  Sentence: 1           have  VBP   O\n",
              "4  Sentence: 1        marched  VBN   O"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5yeVtCW2e9T",
        "outputId": "64613897-e227-474a-fa08-b09812fcfb7b"
      },
      "source": [
        "# POS 종류\n",
        "df_data.POS.unique()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NNS', 'IN', 'VBP', 'VBN', 'NNP', 'TO', 'VB', 'DT', 'NN', 'CC',\n",
              "       'JJ', '.', 'VBD', 'WP', '``', 'CD', 'PRP', 'VBZ', 'POS', 'VBG',\n",
              "       'RB', ',', 'WRB', 'PRP$', 'MD', 'WDT', 'JJR', ':', 'JJS', 'WP$',\n",
              "       'RP', 'PDT', 'NNPS', 'EX', 'RBS', 'LRB', 'RRB', '$', 'RBR', ';',\n",
              "       'UH', 'FW'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXNNJewT3WyQ",
        "outputId": "5c8c7ed7-7bf9-4435-cbc7-e37d1f2b6478"
      },
      "source": [
        "# Tag 종류\n",
        "df_data.Tag.unique()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['O', 'B-geo', 'B-gpe', 'B-per', 'I-geo', 'B-org', 'I-org', 'B-tim',\n",
              "       'B-art', 'I-art', 'I-per', 'I-gpe', 'I-tim', 'B-nat', 'B-eve',\n",
              "       'I-eve', 'I-nat'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfQZhsIX4HSF"
      },
      "source": [
        "* B : Begin. 객체 명이 시작되는 부분\n",
        "* I : Inside. 객체 명의 내부 부분\n",
        "* O : Outside. 객체 명이 아닌 부분\n",
        "* time : time\n",
        "* per : person. 인명\n",
        "* geo : geography. 지역명\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCzPHoJr37m3",
        "outputId": "2a97697d-d195-4348-8aa0-5e44f2055a1f"
      },
      "source": [
        "# 태그 분포\n",
        "df_data.Tag.value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O        887908\n",
              "B-geo     37644\n",
              "B-tim     20333\n",
              "B-org     20143\n",
              "I-per     17251\n",
              "B-per     16990\n",
              "I-org     16784\n",
              "B-gpe     15870\n",
              "I-geo      7414\n",
              "I-tim      6528\n",
              "B-art       402\n",
              "B-eve       308\n",
              "I-art       297\n",
              "I-eve       253\n",
              "B-nat       201\n",
              "I-gpe       198\n",
              "I-nat        51\n",
              "Name: Tag, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8g5AJnT3-y0"
      },
      "source": [
        "#### 데이터 개요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFf4qo2-3a0l",
        "outputId": "2961dbfa-a2a6-4e52-b31c-b600e1b95208"
      },
      "source": [
        "print('총 문장의 수 :', df_data['Sentence #'].nunique())\n",
        "print('총 단어의 수 :', df_data.Word.nunique())\n",
        "print('POS 종류 :', df_data.POS.nunique())\n",
        "print('Tag 종류 :', df_data.Tag.nunique())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 문장의 수 : 47959\n",
            "총 단어의 수 : 35178\n",
            "POS 종류 : 42\n",
            "Tag 종류 : 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spYcluz65EB_"
      },
      "source": [
        "## 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTA-XO5m5Frh"
      },
      "source": [
        "### 데이터를 문서 구조로 parsing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "219L0SSd35eG"
      },
      "source": [
        "class SentenceGetter(object):\n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n",
        "                                                           s['POS'].values.tolist(),\n",
        "                                                           s['Tag'].values.tolist())]\n",
        "  \n",
        "        self.grouped = self.data.groupby('Sentence #').apply(agg_func)  # 데이터를 문장 단위로 구분, 각 행(단어) 마다 agg_func 적용\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "\n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped['Sentence: {}'.format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "\n",
        "        except:\n",
        "          return None"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgg_2VLh8QJb"
      },
      "source": [
        "#### SentenceGetter 보충 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "eKDa2R3A7mnb",
        "outputId": "92d93179-c20e-4f69-8c06-dcbbd05025c5"
      },
      "source": [
        "# self.grouped의 한 예 (첫번 째 문장)\n",
        "data = df_data.loc[df_data['Sentence #'] == 'Sentence: 1']\n",
        "data.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag\n",
              "0  Sentence: 1      Thousands  NNS   O\n",
              "1  Sentence: 1             of   IN   O\n",
              "2  Sentence: 1  demonstrators  NNS   O\n",
              "3  Sentence: 1           have  VBP   O\n",
              "4  Sentence: 1        marched  VBN   O"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0MWu2RA7mqD",
        "outputId": "948b2be3-8bd7-4b0a-8789-166caf18db07"
      },
      "source": [
        "# self.sentences의 한 예 (첫번 째 문장에 agg_func 적용)\n",
        "# (단어, POS, Tag) 튜플로 구성\n",
        "[(w, p, t) for w, p, t in zip(data['Word'].values.tolist(),\n",
        "                              data['POS'].values.tolist(),\n",
        "                              data['Tag'].values.tolist())]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Thousands', 'NNS', 'O'),\n",
              " ('of', 'IN', 'O'),\n",
              " ('demonstrators', 'NNS', 'O'),\n",
              " ('have', 'VBP', 'O'),\n",
              " ('marched', 'VBN', 'O'),\n",
              " ('through', 'IN', 'O'),\n",
              " ('London', 'NNP', 'B-geo'),\n",
              " ('to', 'TO', 'O'),\n",
              " ('protest', 'VB', 'O'),\n",
              " ('the', 'DT', 'O'),\n",
              " ('war', 'NN', 'O'),\n",
              " ('in', 'IN', 'O'),\n",
              " ('Iraq', 'NNP', 'B-geo'),\n",
              " ('and', 'CC', 'O'),\n",
              " ('demand', 'VB', 'O'),\n",
              " ('the', 'DT', 'O'),\n",
              " ('withdrawal', 'NN', 'O'),\n",
              " ('of', 'IN', 'O'),\n",
              " ('British', 'JJ', 'B-gpe'),\n",
              " ('troops', 'NNS', 'O'),\n",
              " ('from', 'IN', 'O'),\n",
              " ('that', 'DT', 'O'),\n",
              " ('country', 'NN', 'O'),\n",
              " ('.', '.', 'O')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qligobkz6XGI",
        "outputId": "6cf89108-9f95-4059-ec0f-2ce9f1173a67"
      },
      "source": [
        "# 전체 데이터(모든 문장)에 적용\n",
        "getter = SentenceGetter(df_data)\n",
        "getter"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.SentenceGetter at 0x7f604a945e10>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DePIR6aL6Zi0",
        "outputId": "0fcc0977-d5b7-4b12-b2c0-b8b03b9a4073"
      },
      "source": [
        "# getter.sentences는 모든 문장들에 대한 (w, p, t) 튜플들로 구성. \n",
        "# sent는 두칸 위 셀의 결과와 같은 형식으로 표현됨. s는 sent를 구성하는 (w, p, t) 튜플\n",
        "sentences = [[s[0] for s in sent] for sent in getter.sentences]\n",
        "sentences[0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Thousands',\n",
              " 'of',\n",
              " 'demonstrators',\n",
              " 'have',\n",
              " 'marched',\n",
              " 'through',\n",
              " 'London',\n",
              " 'to',\n",
              " 'protest',\n",
              " 'the',\n",
              " 'war',\n",
              " 'in',\n",
              " 'Iraq',\n",
              " 'and',\n",
              " 'demand',\n",
              " 'the',\n",
              " 'withdrawal',\n",
              " 'of',\n",
              " 'British',\n",
              " 'troops',\n",
              " 'from',\n",
              " 'that',\n",
              " 'country',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTLEn-h16ceJ",
        "outputId": "d31a973e-54e8-4fe2-ed9d-4527e7f0958c"
      },
      "source": [
        "poses = [[s[1] for s in sent] for sent in getter.sentences]\n",
        "print(poses[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP', 'TO', 'VB', 'DT', 'NN', 'IN', 'NNP', 'CC', 'VB', 'DT', 'NN', 'IN', 'JJ', 'NNS', 'IN', 'DT', 'NN', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i0FJxFG8pSg",
        "outputId": "fb557037-5b73-4ad3-923d-e282999c402f"
      },
      "source": [
        "labels = [[s[2] for s in sent] for sent in getter.sentences]\n",
        "print(labels[0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdEgVRl29TDM"
      },
      "source": [
        "#### Tag를 index로 전환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9eEWZ948r14",
        "outputId": "e9548516-771d-42e6-f33b-5c3bd21f69b1"
      },
      "source": [
        "# 모든 태그 종류\n",
        "tags_vals = list(set(df_data['Tag'].values))\n",
        "tags_vals"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I-art',\n",
              " 'B-tim',\n",
              " 'I-per',\n",
              " 'B-nat',\n",
              " 'I-tim',\n",
              " 'B-eve',\n",
              " 'B-gpe',\n",
              " 'B-org',\n",
              " 'I-org',\n",
              " 'I-geo',\n",
              " 'O',\n",
              " 'B-geo',\n",
              " 'B-per',\n",
              " 'B-art',\n",
              " 'I-gpe',\n",
              " 'I-nat',\n",
              " 'I-eve']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rADVotxA9GGn"
      },
      "source": [
        "tags_vals.append('X')  # wordpiece용\n",
        "tags_vals.append('[CLS]')  # BERT 구분자\n",
        "tags_vals.append('[SEP]')  # BERT 구분자"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44fyArf79Kw0"
      },
      "source": [
        "tags_vals = set(tags_vals)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRCT_PDb9MCw",
        "outputId": "f802de78-2151-4d48-e313-4f00b3555fea"
      },
      "source": [
        "tags_vals"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-art',\n",
              " 'B-eve',\n",
              " 'B-geo',\n",
              " 'B-gpe',\n",
              " 'B-nat',\n",
              " 'B-org',\n",
              " 'B-per',\n",
              " 'B-tim',\n",
              " 'I-art',\n",
              " 'I-eve',\n",
              " 'I-geo',\n",
              " 'I-gpe',\n",
              " 'I-nat',\n",
              " 'I-org',\n",
              " 'I-per',\n",
              " 'I-tim',\n",
              " 'O',\n",
              " 'X',\n",
              " '[CLS]',\n",
              " '[SEP]'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7N_Bo1C9NH6"
      },
      "source": [
        "# tag를 index로 매핑하는 딕셔너리\n",
        "# tag2idx = {t: i for i, t in enumerate(tags_vals)}\n",
        "\n",
        "tag2idx={'B-art': 14,\n",
        "         'B-eve': 16,\n",
        "         'B-geo': 0,\n",
        "         'B-gpe': 13,\n",
        "         'B-nat': 12,\n",
        "         'B-org': 10,\n",
        "         'B-per': 4,\n",
        "         'B-tim': 2,\n",
        "         'I-art': 5,\n",
        "         'I-eve': 7,\n",
        "         'I-geo': 15,\n",
        "         'I-gpe': 8,\n",
        "         'I-nat': 11,\n",
        "         'I-org': 3,\n",
        "         'I-per': 6,\n",
        "         'I-tim': 1,\n",
        "         'X':17,\n",
        "         'O': 9,\n",
        "         '[CLS]':18,\n",
        "         '[SEP]':19}"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM7sSiMW9ui0"
      },
      "source": [
        "# index를 tag로 매핑\n",
        "tag2name={tag2idx[key] : key for key in tag2idx.keys()}"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xA3wigV91Jo",
        "outputId": "40043fda-5603-4708-e2e0-1f28a532fc24"
      },
      "source": [
        "tag2name"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'B-geo',\n",
              " 1: 'I-tim',\n",
              " 2: 'B-tim',\n",
              " 3: 'I-org',\n",
              " 4: 'B-per',\n",
              " 5: 'I-art',\n",
              " 6: 'I-per',\n",
              " 7: 'I-eve',\n",
              " 8: 'I-gpe',\n",
              " 9: 'O',\n",
              " 10: 'B-org',\n",
              " 11: 'I-nat',\n",
              " 12: 'B-nat',\n",
              " 13: 'B-gpe',\n",
              " 14: 'B-art',\n",
              " 15: 'I-geo',\n",
              " 16: 'B-eve',\n",
              " 17: 'X',\n",
              " 18: '[CLS]',\n",
              " 19: '[SEP]'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgNKUyE7-MMu"
      },
      "source": [
        "## 학습 데이터 구축\n",
        "\n",
        "* 사전 학습된 Tokenizer 활용\n",
        "* 입력 임베딩 구축 : token embedding, mask word embedding, segmentation embedding\n",
        "* 학습, 검증, 테스트 데이터를 dataloader에 전달"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNSFQKMH962T",
        "outputId": "2bfe9193-36b3-479f-82db-b19287b32d25"
      },
      "source": [
        "# gpu 환경 구축\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "n_gpu"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFjMzIim-n8d"
      },
      "source": [
        "### Tokenize\n",
        "\n",
        "사전 학습된 Tokenizer 다운로드 : https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVDgtXFT-dkJ"
      },
      "source": [
        "# tokenizer 불러오기\n",
        "vocabulary = \"/content/drive/My Drive/vocab.txt\""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1pczNbcA673"
      },
      "source": [
        "# 모델의 max_position_embedding인 512보다 작아야함\n",
        "max_len  = 45"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9XJbAAKA_76",
        "outputId": "f8232b87-0586-45d5-8a82-cdea870e2eca"
      },
      "source": [
        "# tokenizer 로드\n",
        "tokenizer = BertTokenizer(vocab_file=vocabulary, do_lower_case=False)  # 대소문자를 구분함\n",
        "tokenizer"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<transformers.tokenization_bert.BertTokenizer at 0x7f6042174890>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu6jMaF6BBaU",
        "outputId": "dac07609-cc65-4e90-d861-7449f8042957"
      },
      "source": [
        "tokenized_texts = []\n",
        "word_piece_labels = []\n",
        "i_inc = 0\n",
        "\n",
        "# word_list : 문장을 구성하는 단어들의 리스트\n",
        "# label : 해당 단어들의 tag label\n",
        "for word_list, label in (zip(sentences, labels)):  \n",
        "    temp_label = []\n",
        "    temp_token = []\n",
        "    \n",
        "    # 문장 시작에 [CLS] 토큰 추가\n",
        "    temp_label.append('[CLS]')\n",
        "    temp_token.append('[CLS]')\n",
        "    \n",
        "    # Tokenize : 문장을 구성하는 모든 단어들을 사전 학습된 Tokenize를 활용하여 토큰화\n",
        "    for word, lab in zip(word_list, label):\n",
        "        token_list = tokenizer.tokenize(word)\n",
        "        for m, token in enumerate(token_list):\n",
        "            temp_token.append(token)\n",
        "            if m == 0:\n",
        "                temp_label.append(lab)\n",
        "\n",
        "            # ##tra, ##A 같은 형식은 X로 라벨링    \n",
        "            else:\n",
        "                temp_label.append('X')\n",
        "\n",
        "    # 문장 마지막 부분에 [SEP] 토큰 추가\n",
        "    temp_label.append('[SEP]')\n",
        "    temp_token.append('[SEP]')\n",
        "\n",
        "    tokenized_texts.append(temp_token)\n",
        "    word_piece_labels.append(temp_label)\n",
        "\n",
        "    if 5 > i_inc:\n",
        "        print(\"No.%d,len:%d\"%(i_inc,len(temp_token)))\n",
        "        print(\"texts:%s\"%(\" \".join(temp_token)))\n",
        "        print(\"No.%d,len:%d\"%(i_inc,len(temp_label)))\n",
        "        print(\"lables:%s\"%(\" \".join(temp_label)))\n",
        "        print()\n",
        "\n",
        "    i_inc +=1"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No.0,len:28\n",
            "texts:[CLS] Thousands of demons ##tra ##tors have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country . [SEP]\n",
            "No.0,len:28\n",
            "lables:[CLS] O O O X X O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O [SEP]\n",
            "\n",
            "No.1,len:29\n",
            "texts:[CLS] Iranian officials say they expect to get access to sealed sensitive parts of the plant Wednesday , after an I ##A ##EA surveillance system begins functioning . [SEP]\n",
            "No.1,len:29\n",
            "lables:[CLS] B-gpe O O O O O O O O O O O O O O B-tim O O O B-org X X O O O O O [SEP]\n",
            "\n",
            "No.2,len:44\n",
            "texts:[CLS] He ##lic ##op ##ter guns ##hips Saturday pounded militant hide ##outs in the Or ##ak ##zai tribal region , where many Taliban militants are believed to have fled to avoid an earlier military offensive in nearby South W ##azi ##rist ##an . [SEP]\n",
            "No.2,len:44\n",
            "lables:[CLS] O X X X O X B-tim O O O X O O B-geo X X O O O O O B-org O O O O O O O O O O O O O O B-geo I-geo X X X O [SEP]\n",
            "\n",
            "No.3,len:16\n",
            "texts:[CLS] They left after a tense hour - long stand ##off with riot police . [SEP]\n",
            "No.3,len:16\n",
            "lables:[CLS] O O O O O O X X O X O O O O [SEP]\n",
            "\n",
            "No.4,len:47\n",
            "texts:[CLS] U . N . relief coordinator Jan E ##gel ##and said Sunday , U . S . , Indonesian and Australian military helicopters are ferry ##ing out food and supplies to remote areas of western Ace ##h province that ground crews can not reach . [SEP]\n",
            "No.4,len:47\n",
            "lables:[CLS] B-geo X X X O O B-per I-per X X O B-tim O B-geo X X X O B-gpe O B-gpe O O O O X O O O O O O O O O B-geo X O O O O O O O O [SEP]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRqDX7l8C2mz"
      },
      "source": [
        "#### Tokenize 보충"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5NVKkxXBCwo",
        "outputId": "a42f9f66-b15c-438f-b4cd-52aff57d608d"
      },
      "source": [
        "# 첫 번째 문장\n",
        "word_list = sentences[0]\n",
        "label = labels[0]\n",
        "\n",
        "temp_label = [] ; temp_token = []\n",
        "temp_label.append('[CLS]') ; temp_token.append('[CLS]')\n",
        "\n",
        "# 초기 상태\n",
        "print(temp_label)\n",
        "print(temp_token)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]']\n",
            "['[CLS]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iL0Uy3qQEp0p",
        "outputId": "fa8c4dd6-ca4a-4e11-b819-8d3effcb66f5"
      },
      "source": [
        "# 첫 번째 문장의 단어, tag 라벨들\n",
        "print(word_list)\n",
        "print(label)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wY0QRiSEjUn",
        "outputId": "ef120af0-46d8-46fe-cd65-7f689d11ca80"
      },
      "source": [
        "# 첫 번째 문장의 단어들을 사전학습된 토크나이저로 토큰화\n",
        "for word, lab in zip(word_list, label):\n",
        "    token_list = tokenizer.tokenize(word)\n",
        "    print('단어 토큰 :', token_list, '/', 'Tag 라벨 :', lab)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 토큰 : ['Thousands'] / Tag 라벨 : O\n",
            "단어 토큰 : ['of'] / Tag 라벨 : O\n",
            "단어 토큰 : ['demons', '##tra', '##tors'] / Tag 라벨 : O\n",
            "단어 토큰 : ['have'] / Tag 라벨 : O\n",
            "단어 토큰 : ['marched'] / Tag 라벨 : O\n",
            "단어 토큰 : ['through'] / Tag 라벨 : O\n",
            "단어 토큰 : ['London'] / Tag 라벨 : B-geo\n",
            "단어 토큰 : ['to'] / Tag 라벨 : O\n",
            "단어 토큰 : ['protest'] / Tag 라벨 : O\n",
            "단어 토큰 : ['the'] / Tag 라벨 : O\n",
            "단어 토큰 : ['war'] / Tag 라벨 : O\n",
            "단어 토큰 : ['in'] / Tag 라벨 : O\n",
            "단어 토큰 : ['Iraq'] / Tag 라벨 : B-geo\n",
            "단어 토큰 : ['and'] / Tag 라벨 : O\n",
            "단어 토큰 : ['demand'] / Tag 라벨 : O\n",
            "단어 토큰 : ['the'] / Tag 라벨 : O\n",
            "단어 토큰 : ['withdrawal'] / Tag 라벨 : O\n",
            "단어 토큰 : ['of'] / Tag 라벨 : O\n",
            "단어 토큰 : ['British'] / Tag 라벨 : B-gpe\n",
            "단어 토큰 : ['troops'] / Tag 라벨 : O\n",
            "단어 토큰 : ['from'] / Tag 라벨 : O\n",
            "단어 토큰 : ['that'] / Tag 라벨 : O\n",
            "단어 토큰 : ['country'] / Tag 라벨 : O\n",
            "단어 토큰 : ['.'] / Tag 라벨 : O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpAc7id9DYcA",
        "outputId": "3c9ef09f-2f79-47e8-c4c5-3590d2fcf72f"
      },
      "source": [
        "for word, lab in zip(word_list, label):\n",
        "    token_list = tokenizer.tokenize(word)\n",
        "    for m, token in enumerate(token_list):\n",
        "        temp_token.append(token)\n",
        "        if m == 0:  # 위 결과의 개별 리스트에서 첫 번째 토큰들\n",
        "            temp_label.append(lab)\n",
        "        else:  # 위 결과의 개별 리스트에서 첫 번째 가 아닌 토큰들 ex) ##tra\n",
        "            temp_label.append('X')\n",
        "\n",
        "print(temp_label)\n",
        "print(temp_token)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'O', 'O', 'O', 'X', 'X', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n",
            "['[CLS]', 'Thousands', 'of', 'demons', '##tra', '##tors', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPrQwbgHHFuo"
      },
      "source": [
        "### Token Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ubXLZ-fD-Oy",
        "outputId": "d2b1e2c0-2dde-4506-b702-bb61704e3981"
      },
      "source": [
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],  # convert_tokens_to_ids : 토큰 인덱스들의 리스트를 반환\n",
        "                           maxlen=max_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print(input_ids[0])\n",
        "# 시퀀스 패딩으로 길이 동일\n",
        "print(len(input_ids[0]))\n",
        "print(len(input_ids[1]))\n",
        "print(len(input_ids[2]))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  101 26159  1104  8568  4487  5067  1138  9639  1194  1498  1106  5641\n",
            "  1103  1594  1107  5008  1105  4555  1103 10602  1104  1418  2830  1121\n",
            "  1115  1583   119   102     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0]\n",
            "45\n",
            "45\n",
            "45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vNBq16-R4d7",
        "outputId": "d669ad81-ce6f-4892-e853-cb09da3f3f3c"
      },
      "source": [
        "print(tokenizer.convert_tokens_to_ids(tokenized_texts[0]))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 26159, 1104, 8568, 4487, 5067, 1138, 9639, 1194, 1498, 1106, 5641, 1103, 1594, 1107, 5008, 1105, 4555, 1103, 10602, 1104, 1418, 2830, 1121, 1115, 1583, 119, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bEa1v-IH-Uk"
      },
      "source": [
        "Tokenizer 기능, 옵션 참고 : https://huggingface.co/transformers/main_classes/tokenizer.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFrkSioqKQ67",
        "outputId": "8e681203-0926-4b16-e017-46cd0214376c"
      },
      "source": [
        "# Tag 라벨을 인덱스로 변환\n",
        "# 동일한 길이로 패딩 ('O' : Others)\n",
        "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in word_piece_labels],\n",
        "                       maxlen=max_len, value=tag2idx[\"O\"], padding=\"post\", dtype=\"long\", truncating=\"post\")\n",
        "\n",
        "print(tags[0])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18  9  9  9 17 17  9  9  9  0  9  9  9  9  9  0  9  9  9  9  9 13  9  9\n",
            "  9  9  9 19  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj6H_KDBHW--",
        "outputId": "25d35810-2a42-437a-bd35-ed3158844e1d"
      },
      "source": [
        "txt = tokenized_texts[1]\n",
        "print(txt)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'Iranian', 'officials', 'say', 'they', 'expect', 'to', 'get', 'access', 'to', 'sealed', 'sensitive', 'parts', 'of', 'the', 'plant', 'Wednesday', ',', 'after', 'an', 'I', '##A', '##EA', 'surveillance', 'system', 'begins', 'functioning', '.', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2vUeiAgI7Kf"
      },
      "source": [
        "### Mask Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ-7xIP-Izpb",
        "outputId": "bb957799-a32f-4806-c244-9effe377e1b8"
      },
      "source": [
        "# 0보다 큰 경우 (실제 단어 토큰인 경우) 1, 0인 경우(패딩값) 0\n",
        "attention_masks = [[int(i>0) for i in ii] for ii in input_ids]\n",
        "print(attention_masks[0])  # 28번째 까지가 1"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jWa0zYxI_Ja",
        "outputId": "c7c53301-cff2-4557-941a-d0f1bd5ca28e"
      },
      "source": [
        "ii = input_ids[0]  # 28번째 까지가 실제 단어 토큰의 인덱스\n",
        "ii"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101, 26159,  1104,  8568,  4487,  5067,  1138,  9639,  1194,\n",
              "        1498,  1106,  5641,  1103,  1594,  1107,  5008,  1105,  4555,\n",
              "        1103, 10602,  1104,  1418,  2830,  1121,  1115,  1583,   119,\n",
              "         102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnN5xY3TJopu"
      },
      "source": [
        "### Segment Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCxBmLVEJJWX",
        "outputId": "6958ff9e-356a-46e1-e803-af5fb48d0281"
      },
      "source": [
        "# 한 문장이기 때문에 0으로만 임베딩됨\n",
        "# 문장 태깅 태스크에서는 불필요한 작업\n",
        "segment_ids = [[0] * len(input_id) for input_id in input_ids]\n",
        "print(segment_ids[0])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PupMxIqjJ75i"
      },
      "source": [
        "## 데이터 분할 & 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVHuUvxMLQZD",
        "outputId": "49dcbbf5-bff7-4d9b-b468-08fd0b2852d2"
      },
      "source": [
        "tags"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[18,  9,  9, ...,  9,  9,  9],\n",
              "       [18, 13,  9, ...,  9,  9,  9],\n",
              "       [18,  9, 17, ...,  9, 19,  9],\n",
              "       ...,\n",
              "       [18,  9,  0, ...,  9,  9,  9],\n",
              "       [18,  9,  9, ...,  9,  9,  9],\n",
              "       [18,  9, 10, ...,  9,  9,  9]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieLz6RcvTKpj",
        "outputId": "a286a556-68a7-46a3-820c-1d20467b08b2"
      },
      "source": [
        "# 토큰화가 완료된 전체 텍스트 데이터는 47959개의 문장이 있음\n",
        "# 개별 문장들은 동일한 길이 45를 갖는 토큰들의 시퀀스로 표현되고, 개별 토큰들에 대응되는 tag가 존재\n",
        "print(tags.shape)\n",
        "print(len(tokenized_texts))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(47959, 45)\n",
            "47959\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1HRLfJqJtsE",
        "outputId": "e34c6440-09b0-48d4-bdc4-5fcad202a5fe"
      },
      "source": [
        "tr_inputs, val_inputs, tr_tags, val_tags, tr_masks, val_masks,tr_segs, val_segs = train_test_split(input_ids, tags, attention_masks, segment_ids, \n",
        "                                                                                                   random_state=4, test_size=0.3)\n",
        "\n",
        "len(tr_inputs), len(val_inputs), len(tr_segs), len(val_segs)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33571, 14388, 33571, 14388)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB4BSTG6T2DX",
        "outputId": "0e7f9fc9-d405-41dd-f06e-04da281da233"
      },
      "source": [
        "tr_inputs # array"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  101,   138,  5680, ...,     0,     0,     0],\n",
              "       [  101, 14381,  1555, ...,     0,     0,     0],\n",
              "       [  101,  1828,   119, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  101,  1124,  1145, ...,     0,     0,     0],\n",
              "       [  101, 13364,   112, ...,     0,     0,     0],\n",
              "       [  101,  1109,  3948, ...,  3906,  3702,  2410]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hft_VMXVLwR1"
      },
      "source": [
        "# 텐서로 변환\n",
        "tr_inputs = torch.tensor(tr_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "tr_tags = torch.tensor(tr_tags)\n",
        "val_tags = torch.tensor(val_tags)\n",
        "tr_masks = torch.tensor(tr_masks)\n",
        "val_masks = torch.tensor(val_masks)\n",
        "tr_segs = torch.tensor(tr_segs)\n",
        "val_segs = torch.tensor(val_segs)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDw2sDivTzVk",
        "outputId": "c8f0ba8e-3538-41f5-9cf5-dc8487c4bdbe"
      },
      "source": [
        "tr_inputs # tensor"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,   138,  5680,  ...,     0,     0,     0],\n",
              "        [  101, 14381,  1555,  ...,     0,     0,     0],\n",
              "        [  101,  1828,   119,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  101,  1124,  1145,  ...,     0,     0,     0],\n",
              "        [  101, 13364,   112,  ...,     0,     0,     0],\n",
              "        [  101,  1109,  3948,  ...,  3906,  3702,  2410]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRS8pWqgKHYz"
      },
      "source": [
        "batch_num = 32"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a7y-0ySKJWg"
      },
      "source": [
        "# 토큰 임베딩, 어텐션 임베딩만 포함\n",
        "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
        "train_sampler = RandomSampler(train_data)  # 각 데이터를 랜덤하게 가져옴\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_num, drop_last=True)\n",
        "# batch 단위로 데이터를 불러올 경우, batch_size에 따라 마지막 batch의 길이가 달라질 수 있음. \n",
        "# ex) data의 개수는 27개인데, batch_size가 5라면 마지막 batch의 크기는 2가 됨.\n",
        "# 이 때 마지막 배치를 사용하지 않음 (배치 크기에 의존도가 높은 손실 함수를 사용하는 경우 권장됨)\n",
        "\n",
        "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_num)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EH1q8UaMg-9"
      },
      "source": [
        "## 학습\n",
        "\n",
        "pytorch_model.bin 다운로드 : https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin\n",
        "\n",
        "config.json 다운로드 : https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "a9d3262a8d1843dcaae43048afa6f6d4",
            "7bc67a4bed4c4ea19bf2f124e6be5a71",
            "2962d3225e5a40aeb0af90d9d9e74e9a",
            "09ca27f4e21e4dbf80df7aa84fc427f3",
            "7ee559cf84a84816894734750592c5c6",
            "e1045196b1a34403b19829858dfd55b2",
            "b3002bc0e6aa439f9800571ed7f7be9e",
            "5da66e8ec03b49608477fcc91d2d857b",
            "3815be4fa92d4a318f8a82657994ba4d",
            "b0e782bd3e04422d8e856fcc86cdb4d6",
            "d44e7f4a4906465c832753f238fd8ded",
            "2a00596b23ae4017b85c887d1dff6265",
            "6436fed6071d4cc6be0f1f0b82dacf2b",
            "721720b737a24c909ae3847880aba245",
            "8d697e1468bb40e1ba5c295ddefb72f9",
            "98222a40bf4c47e389ed6647bf47addc",
            "5adff03fa897475c8cf4654196ba2566",
            "3f7452b91815480d866e62cd33d5dd45",
            "39576bda35e84108ad0f19a5da12a6f6",
            "e95151e73dd5400bba2ddc988938d86c",
            "e8756282296d49a5b4eb9a275c10feb1",
            "bbadb27a7404452481a0ffed99b61001"
          ]
        },
        "id": "ss6GfB4NLqBC",
        "outputId": "10510cd3-5fa5-4461-a6ea-793f916cacd5"
      },
      "source": [
        "# 사전 학습된 모델 불러오기\n",
        "model = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=len(tag2idx))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9d3262a8d1843dcaae43048afa6f6d4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a00596b23ae4017b85c887d1dff6265",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cz0s8FzoMqbV",
        "outputId": "7dfe8af6-e6d8-4bb1-e424-3e77a65d031b"
      },
      "source": [
        "# 모델에 GPT 세팅\n",
        "model.cuda()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1)\n",
              "  (classifier): Linear(in_features=768, out_features=20, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6yZYjH2RnpG"
      },
      "source": [
        "# GPU가 여러개면 \n",
        "if n_gpu >1:\n",
        "    model = torch.nn.DataParallel(model)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrKKTX9uRvZl"
      },
      "source": [
        "epochs = 5\n",
        "max_grad_norm = 1.0\n",
        "# train optimization num\n",
        "num_train_optimization_steps = int(math.ceil(len(tr_inputs) / batch_num) / 1) * epochs"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6ta6i2yR_dk"
      },
      "source": [
        "### Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJap958mR6mI"
      },
      "source": [
        "# True : 모든 layer를 미세 조정\n",
        "# False : 분류기 레이어만 미세 조정\n",
        "FULL_FINETUNING = True"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfKSpehRSM7y"
      },
      "source": [
        "if FULL_FINETUNING:\n",
        "    # 모든 레이어의 파라미터들을 미세 조정\n",
        "    param_optimizer = list(model.named_parameters())  # (name, parameter) 조합의 tuple iterator 반환\n",
        "    no_decay = ['bias', 'gamma', 'beta']  # 가중치 감쇠를 적용하지 않는 파라미터들\n",
        "    optimizer_grouped_parameters = [\n",
        "        # 가중치 감쇠 적용                            \n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],  # n : 파라미터 이름 / p: 실제 가중치 행렬\n",
        "         'weight_decay_rate': 0.01},\n",
        "        # 가중치 감쇠 미적용\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "\n",
        "else:\n",
        "    # 분류기 레이어의 파라미터만 미세조정\n",
        "    param_optimizer = list(model.classifier.named_parameters()) \n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOaW9ljdYVmD",
        "outputId": "d04d0837-a112-44de-ee41-a14553808843"
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "[n for n, p in param_optimizer][:4]"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bert.embeddings.word_embeddings.weight',\n",
              " 'bert.embeddings.position_embeddings.weight',\n",
              " 'bert.embeddings.token_type_embeddings.weight',\n",
              " 'bert.embeddings.LayerNorm.weight']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UerExmdDYZ5d",
        "outputId": "87c419cf-398a-45c3-c8b9-67f578865313"
      },
      "source": [
        "# 가중치 감쇠 적용\n",
        "n = 'bert.embeddings.word_embeddings.weight' \n",
        "not any(nd in n for nd in no_decay)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpnein1QYaAx",
        "outputId": "fc5618cc-4e5a-4077-beec-94819d6f71dd"
      },
      "source": [
        "# 가중치 감쇠 미적용\n",
        "n = 'bias' \n",
        "any(nd in n for nd in no_decay)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxQX7ukvXBY9"
      },
      "source": [
        "weight_decay(가중치 감쇠) : 과적합 문제를 해결하기 위한 규제화. 학습 중 가중치가 너무 큰 값을 가지지 않도록 제한하여 모델의 복잡도를 감소시킴."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jURJ7fv9WMUz"
      },
      "source": [
        "torch에서 파라미터 접근하기 참고 : https://soundprovider.tistory.com/entry/pytorch-torch%EC%97%90%EC%84%9C-parameter-%EC%A0%91%EA%B7%BC%ED%95%98%EA%B8%B0\n",
        "\n",
        "weight_decay 참고 \n",
        "\n",
        "https://deepapple.tistory.com/6\n",
        "\n",
        "https://ko.d2l.ai/chapter_deep-learning-basics/weight-decay.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0XUc9EPSbpY"
      },
      "source": [
        "model.train();"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKIXPQB6SqDk",
        "outputId": "b4d26a36-1298-424e-c348-f522088eb888"
      },
      "source": [
        "print(\"***** Running training *****\")\n",
        "print(\"  Num examples = %d\"%(len(tr_inputs)))\n",
        "print(\"  Batch size = %d\"%(batch_num))\n",
        "print(\"  Num steps = %d\"%(num_train_optimization_steps))\n",
        "for _ in trange(epochs,desc=\"Epoch\"):\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # batch에 gpu 할당\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch  # 토큰 임베딩, 마스크 임베딩, tag 라벨\n",
        "        \n",
        "        # forward \n",
        "        outputs = model(b_input_ids, token_type_ids=None,\n",
        "                        attention_mask=b_input_mask, labels=b_labels)\n",
        "        # 손실 함수 계산\n",
        "        loss, scores = outputs[:2]\n",
        "        if n_gpu>1:\n",
        "            # gpu를 여러 개 사용하는 경우 평균\n",
        "            loss = loss.mean()\n",
        "\n",
        "        # backward : 모든 파라미터에 대해 loss의 변화도(gradient) 계산\n",
        "        loss.backward()\n",
        "        \n",
        "        # track train loss\n",
        "        tr_loss += loss.item()  # 손실이 가지고 있는 스칼라 값\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "        \n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        \n",
        "        # 파라미터 업데이트\n",
        "        optimizer.step()  # optimizer가 업데이트할 파라미터와 학습률, 하이퍼 파라미터 등을 받아 업데이트 (argument로 전달받은 파라미터 업데이트)\n",
        "        optimizer.zero_grad()  # 한 번의 학습이 완료되면 gradient를 0으로 만듬. (loss.backward가 매번 gradient를 더하기 때문) \n",
        "        \n",
        "    # print train loss per epoch\n",
        "    print(\"Train loss: {}\".format(tr_loss / nb_tr_steps))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 33571\n",
            "  Batch size = 32\n",
            "  Num steps = 5250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:  20%|██        | 1/5 [03:30<14:00, 210.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.14344811097348553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  40%|████      | 2/5 [06:58<10:28, 209.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.067771936517326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  60%|██████    | 3/5 [10:28<06:58, 209.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.05264862299185633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  80%|████████  | 4/5 [13:56<03:29, 209.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.039890202472574146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 5/5 [17:25<00:00, 209.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 0.030512325715156427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsnCe_28cGX_"
      },
      "source": [
        "참고 : \n",
        "\n",
        "https://anweh.tistory.com/22\n",
        "\n",
        "https://tutorials.pytorch.kr/beginner/pytorch_with_examples.html\n",
        "\n",
        "https://algopoolja.tistory.com/55\n",
        "\n",
        "https://velog.io/@kjb0531/zerograd%EC%9D%98-%EC%9D%B4%ED%95%B4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94mbrv38S6ka"
      },
      "source": [
        "### 모델 저장 & 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWDDW8g7S4L6"
      },
      "source": [
        "bert_out_address = '/content/drive/My Drive/models/bert_out_model/en09'\n",
        "# 해당 경로가 없으면 만듬\n",
        "if not os.path.exists(bert_out_address):\n",
        "    os.makedirs(bert_out_address)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY1NfJ5KTCtE"
      },
      "source": [
        "model_to_save = model.module if hasattr(model, 'module') else model  \n",
        "# from_pretrained를 사용하여 학습한 모델을 불러올 수 있도록\n",
        "output_model_file = os.path.join(bert_out_address, \"pytorch_model.bin\")\n",
        "output_config_file = os.path.join(bert_out_address, \"config.json\")"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myz8E-dYTCwf",
        "outputId": "81c7884b-d429-460f-ba13-81a62e4fa2c1"
      },
      "source": [
        "torch.save(model_to_save.state_dict(), output_model_file)\n",
        "model_to_save.config.to_json_file(output_config_file)\n",
        "tokenizer.save_vocabulary(bert_out_address)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n",
            "Saving vocabulary to /content/drive/My Drive/models/bert_out_model/en09/vocab.txt: vocabulary indices are not consecutive. Please check that the vocabulary is not corrupted!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/My Drive/models/bert_out_model/en09/vocab.txt',)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69LImIEPTNAq"
      },
      "source": [
        "# from_pretrained를 사용하여 모델 불러오기\n",
        "model = BertForTokenClassification.from_pretrained(bert_out_address, num_labels=len(tag2idx))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cljNueMTNLJ"
      },
      "source": [
        "model.cuda();"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4XfxVMhTR31"
      },
      "source": [
        "if n_gpu >1:\n",
        "    model = torch.nn.DataParallel(model)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi1u05ZdTYwo"
      },
      "source": [
        "## 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ibJfYq2TYHg"
      },
      "source": [
        "model.eval();"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR_roZ1LTbXx",
        "outputId": "9f9e0bee-bf51-4950-a095-55026a59e14f"
      },
      "source": [
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "print(\"***** Running evaluation *****\")\n",
        "print(\"  Num examples ={}\".format(len(val_inputs)))\n",
        "print(\"  Batch size = {}\".format(batch_num))\n",
        "for step, batch in enumerate(valid_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    input_ids, input_mask, label_ids = batch\n",
        "    \n",
        "#     if step > 2:\n",
        "#         break\n",
        "    # 학습된 파라미터 값을 평가하는 단계에서는 gradient를 계산할 필요가 없음 (메모리 사용량 줄이기)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, token_type_ids=None,\n",
        "                        attention_mask=input_mask,)\n",
        "        # For eval mode, the first result of outputs is logits\n",
        "        logits = outputs[0] \n",
        "    \n",
        "    # Get NER predict result\n",
        "    logits = torch.argmax(F.log_softmax(logits, dim=2), dim=2)\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    \n",
        "    # Get NER true result\n",
        "    label_ids = label_ids.to('cpu').numpy()\n",
        "    \n",
        "    # Only predict the real word, mark=0, will not calculate\n",
        "    input_mask = input_mask.to('cpu').numpy()\n",
        "\n",
        "    # Compare the valuable predict result\n",
        "    for i,mask in enumerate(input_mask):\n",
        "        # Real one\n",
        "        temp_1 = []\n",
        "        # Predict one\n",
        "        temp_2 = []\n",
        "        \n",
        "        for j, m in enumerate(mask):\n",
        "            # Mark=0, meaning its a pad word, dont compare\n",
        "            if m:\n",
        "                if tag2name[label_ids[i][j]] != \"X\" and tag2name[label_ids[i][j]] != \"[CLS]\" and tag2name[label_ids[i][j]] != \"[SEP]\" : # Exclude the X label\n",
        "                    temp_1.append(tag2name[label_ids[i][j]])\n",
        "                    temp_2.append(tag2name[logits[i][j]])\n",
        "            else:\n",
        "                break\n",
        "                   \n",
        "        y_true.append(temp_1)\n",
        "        y_pred.append(temp_2)\n",
        "\n",
        "        \n",
        "\n",
        "print(\"f1 socre: %f\"%(f1_score(y_true, y_pred)))\n",
        "print(\"Accuracy score: %f\"%(accuracy_score(y_true, y_pred)))\n",
        "\n",
        "# Get acc , recall, F1 result report\n",
        "report = classification_report(y_true, y_pred,digits=4)\n",
        "\n",
        "# Save the report into file\n",
        "output_eval_file = os.path.join(bert_out_address, \"eval_results.txt\")\n",
        "with open(output_eval_file, \"w\") as writer:\n",
        "    print(\"***** Eval results *****\")\n",
        "    print(\"\\n%s\"%(report))\n",
        "    print(\"f1 socre: %f\"%(f1_score(y_true, y_pred)))\n",
        "    print(\"Accuracy score: %f\"%(accuracy_score(y_true, y_pred)))\n",
        "    \n",
        "    writer.write(\"f1 socre:\\n\")\n",
        "    writer.write(str(f1_score(y_true, y_pred)))\n",
        "    writer.write(\"\\n\\nAccuracy score:\\n\")\n",
        "    writer.write(str(accuracy_score(y_true, y_pred)))\n",
        "    writer.write(\"\\n\\n\")  \n",
        "    writer.write(report)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Running evaluation *****\n",
            "  Num examples =14388\n",
            "  Batch size = 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: X seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 socre: 0.835981\n",
            "Accuracy score: 0.971437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** Eval results *****\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           _     0.0000    0.0000    0.0000         0\n",
            "         art     0.2190    0.1756    0.1949       131\n",
            "         eve     0.3608    0.3846    0.3723        91\n",
            "         geo     0.8599    0.8864    0.8730     11066\n",
            "         gpe     0.9648    0.9418    0.9532      4830\n",
            "         nat     0.5000    0.4490    0.4731        49\n",
            "         org     0.7014    0.7151    0.7082      5954\n",
            "         per     0.7687    0.7999    0.7840      5123\n",
            "         tim     0.8708    0.8695    0.8702      6016\n",
            "\n",
            "   micro avg     0.8295    0.8426    0.8360     33260\n",
            "   macro avg     0.5828    0.5802    0.5810     33260\n",
            "weighted avg     0.8303    0.8426    0.8363     33260\n",
            "\n",
            "f1 socre: 0.835981\n",
            "Accuracy score: 0.971437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPQz5rmKezdS"
      },
      "source": [
        "참고 \n",
        "\n",
        "https://ctkim.tistory.com/147"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoeegMkwTu6Y"
      },
      "source": [
        "## Inference\n",
        "\n",
        "* 학습 완료된 모델, Tokenizer 불러오기\n",
        "* Test query 작성\n",
        "* Test query를 임베딩\n",
        "* 학습 완료된 모델을 사용하여 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW7MYBZGTbgj"
      },
      "source": [
        "tag2idx={'B-art': 14,\n",
        " 'B-eve': 16,\n",
        " 'B-geo': 0,\n",
        " 'B-gpe': 13,\n",
        " 'B-nat': 12,\n",
        " 'B-org': 10,\n",
        " 'B-per': 4,\n",
        " 'B-tim': 2,\n",
        " 'I-art': 5,\n",
        " 'I-eve': 7,\n",
        " 'I-geo': 15,\n",
        " 'I-gpe': 8,\n",
        " 'I-nat': 11,\n",
        " 'I-org': 3,\n",
        " 'I-per': 6,\n",
        " 'I-tim': 1,\n",
        " 'X':17,\n",
        " 'O': 9,\n",
        " '[CLS]':18,\n",
        " '[SEP]':19}"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMPedPhNTygV"
      },
      "source": [
        "tag2name={tag2idx[key] : key for key in tag2idx.keys()}"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lty2K8yTypa"
      },
      "source": [
        "save_model_address = '/content/drive/My Drive/models/bert_out_model/en09'"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7nIFcfhUn4d"
      },
      "source": [
        "save_model = BertForTokenClassification.from_pretrained(save_model_address,num_labels=len(tag2idx))"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2b2mTxcUn_f"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(save_model_address,do_lower_case=False)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Npqoen0UoEo"
      },
      "source": [
        "max_len  = 45"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-MDibZfUoLf"
      },
      "source": [
        "test_query = \"I live in USA, this is my IBM laptop.\"\n",
        "\n",
        "tokenized_texts = []\n",
        "\n",
        "temp_token = []\n",
        "temp_token.append('[CLS]')\n",
        "\n",
        "token_list = tokenizer.tokenize(test_query)\n",
        "for m,token in enumerate(token_list):\n",
        "    temp_token.append(token)\n",
        "\n",
        "# max_len을 만족시킬 수 있도록 Trim\n",
        "if len(temp_token) > max_len-1:\n",
        "    temp_token= temp_token[:max_len-1]\n",
        "\n",
        "temp_token.append('[SEP]')\n",
        "\n",
        "tokenized_texts.append(temp_token)\n",
        "\n",
        "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                           maxlen=max_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "attention_masks = [[int(i>0) for i in ii] for ii in input_ids]\n",
        "\n",
        "segment_ids = [[0] * len(input_id) for input_id in input_ids]\n",
        "\n",
        "\n",
        "input_ids = torch.tensor(input_ids)\n",
        "attention_masks = torch.tensor(attention_masks)\n",
        "segment_ids = torch.tensor(segment_ids)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic6d79IkVE0a"
      },
      "source": [
        "save_model.eval();"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIXDRJU8VE_z"
      },
      "source": [
        "# Get model predict result\n",
        "with torch.no_grad():\n",
        "    outputs = save_model(input_ids, token_type_ids=None,\n",
        "                         attention_mask=None,)\n",
        "    # For eval mode, the first result of outputs is logits\n",
        "    logits = outputs[0]"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ryh-FDnVJoh"
      },
      "source": [
        "predict_results = logits.detach().cpu().numpy()"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVQHASSVVJw-",
        "outputId": "c7bf14ab-3d29-49e7-d6ab-b5d85265c219"
      },
      "source": [
        "predict_results.shape  # 45개(maxlen) 단어들에 대한 태그(길이 20을 갖는) 예측 결과"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 45, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAHlOZQfVMST",
        "outputId": "2e7338ec-405c-4925-ee21-df6d7767cc4c"
      },
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "result_arrays_soft = softmax(predict_results[0])\n",
        "print(result_arrays_soft[0])\n",
        "\n",
        "result_array = result_arrays_soft\n",
        "print(len(result_array))\n",
        "print(len(result_array[0]))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.6366083e-06 8.4673241e-07 1.3927450e-06 4.0952997e-07 8.1400731e-07\n",
            " 5.3468381e-07 4.0680285e-07 3.9700802e-07 2.6337506e-07 4.7035282e-06\n",
            " 4.3789660e-07 1.4495798e-06 1.0580754e-06 8.6076642e-07 8.1541128e-07\n",
            " 5.6287877e-07 4.8961897e-07 6.5683111e-07 5.0704867e-02 8.4139873e-07]\n",
            "45\n",
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhezf7SzVMcy",
        "outputId": "d9dee380-91aa-4328-96ee-c1338e39384d"
      },
      "source": [
        "result_list = np.argmax(result_array,axis=-1)\n",
        "print(result_list)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18  9  9  9  9  9  9 17  9 17  9  9 19  9 17 17 17 17 17 17 17 17 17 17\n",
            " 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17 17]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfs_fWfxVcKD",
        "outputId": "505c5d80-e392-4d07-948f-fe7e0b958a5c"
      },
      "source": [
        "for i, mark in enumerate(attention_masks[0]):\n",
        "    if mark>0:\n",
        "        print(\"Token:%s\"%(temp_token[i]))\n",
        "#         print(\"Tag:%s\"%(result_list[i]))\n",
        "        print(\"Predict_Tag:%s\"%(tag2name[result_list[i]]))\n",
        "        #print(\"Posibility:%f\"%(result_array[i][result_list[i]]))\n",
        "        print()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token:[CLS]\n",
            "Predict_Tag:[CLS]\n",
            "\n",
            "Token:I\n",
            "Predict_Tag:O\n",
            "\n",
            "Token:live\n",
            "Predict_Tag:O\n",
            "\n",
            "Token:in\n",
            "Predict_Tag:O\n",
            "\n",
            "Token:USA\n",
            "Predict_Tag:O\n",
            "\n",
            "Token:,\n",
            "Predict_Tag:O\n",
            "\n",
            "Token:this\n",
            "Predict_Tag:O\n",
            "\n",
            "Token:is\n",
            "Predict_Tag:X\n",
            "\n",
            "Token:my\n",
            "Predict_Tag:O\n",
            "\n",
            "Token:IBM\n",
            "Predict_Tag:X\n",
            "\n",
            "Token:laptop\n",
            "Predict_Tag:O\n",
            "\n",
            "Token:.\n",
            "Predict_Tag:O\n",
            "\n",
            "Token:[SEP]\n",
            "Predict_Tag:[SEP]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMxmNfHxImwp"
      },
      "source": [
        ""
      ],
      "execution_count": 77,
      "outputs": []
    }
  ]
}