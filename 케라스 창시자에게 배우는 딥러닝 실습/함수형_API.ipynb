{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "함수형 API.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7Rxsm-aJCq-",
        "outputId": "5aa84df6-0d90-4f4e-e45b-682b5cec4e75"
      },
      "source": [
        "! pip install keras==2.2.5"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras==2.2.5\n",
            "  Downloading Keras-2.2.5-py2.py3-none-any.whl (336 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 21.8 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 27.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 30 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 40 kB 29.7 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 51 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 61 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 71 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 81 kB 15.8 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 92 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 102 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 112 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 122 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 133 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 143 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 153 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 163 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 174 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 184 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 194 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 204 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 215 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 225 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 235 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 245 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 256 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 266 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 276 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 286 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 296 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 307 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 317 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 327 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 336 kB 16.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.4.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▌                         | 10 kB 43.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20 kB 49.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 30 kB 58.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 40 kB 62.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 50 kB 8.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.2.5) (1.15.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras==2.2.5) (1.5.2)\n",
            "Installing collected packages: keras-applications, keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.7.0\n",
            "    Uninstalling keras-2.7.0:\n",
            "      Successfully uninstalled keras-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.7.0 requires keras<2.8,>=2.7.0rc0, but you have keras 2.2.5 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-2.2.5 keras-applications-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "zJeKYR2CJIKz",
        "outputId": "be54659f-b93d-46c1-ce7c-52eb1bba98bb"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.5'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roynIgiiJnCH"
      },
      "source": [
        "![Fig7-1-1-1](https://user-images.githubusercontent.com/44194558/142806476-8a492860-463d-4be6-8f0c-53beabdface2.PNG)\n",
        "\n",
        "<br/>\n",
        "\n",
        "![Fig7-1-1-3](https://user-images.githubusercontent.com/44194558/142806630-ab8f2fdb-c033-43a7-9ab1-011726ce16f0.PNG)\n",
        "\n",
        "<br/>\n",
        "\n",
        "* Depthwise : channel wise nxn spatial convolution (5개의 채널 - 5 spatial convolution)\n",
        "\n",
        "* Pointwise : 1x1 convolution to change the dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Xzw_1ZdKFPN"
      },
      "source": [
        "일부 네트워크는 개별 입력이 여러 개 필요하거나 출력이 여러개 필요함\n",
        " - 다양한 입력 소스(Source)에서 전달된 데이터를 다른 종류의 신경망 층을 사용하여 처리하고 합침\n",
        " - 가능한 모든 종류의 입력 데이터를 동시에 사용해서 정확한 하나의 모델을 학습\n",
        "\n",
        "\n",
        "![Fig7-1-3](https://user-images.githubusercontent.com/44194558/142806779-762b48a4-fa18-45b8-8bed-638bdee8a5b5.PNG)\n",
        "\n",
        "<br/>\n",
        "\n",
        "![Fig7-1-4](https://user-images.githubusercontent.com/44194558/142806819-7d817c13-ee63-4ab8-a709-275c833ab037.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsNQw6ZgKwOM"
      },
      "source": [
        "## Multi-tasking\n",
        "\n",
        "\n",
        "입력 데이터에서 여러 개의 타깃 속성을 예측\n",
        "- ex) 소설이나 짧은 글이 있을 때 장르별로 분류 (로맨스, 스릴러 등) + 글을 쓴 대략의 시대를 예측\n",
        "\n",
        "- 2 개의 모델을 개별적으로 훈련 가능 (장르 예측 모델, 시대 예측 모델)\n",
        "\n",
        "But 두 속성은 통계적으로 독립이지 않기 때문에 장르와 시대를 동시에 예측하는 것이 보다 나은 성능을 가져올 수 있음 (2개의 출력/head를 가짐)\n",
        "\n",
        "- 장르와 시대의 상관관계를 고려하여 보다 정확하고 풍부한 representation을 학습\n",
        "- 소설의 시대를 고려하여 장르 공간에서 정확하고 풍부한 표현 학습 (vice versa)\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/44194558/142807253-619a80fd-8676-4020-96df-6aab0e5303d9.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWMU92wjLzMz"
      },
      "source": [
        "최근의 많은 신경망 모델은 비선형 네트워크 topology를 필요로 함\n",
        "- directed acyclic graphs\n",
        "- inception network (입력은 나란히 놓인 여러 개의 합성곱 층을 거쳐 하나의 텐서로 출력이 합쳐짐)\n",
        "\n",
        "\n",
        "![Fig7-1-5-3](https://user-images.githubusercontent.com/44194558/142807449-8b8a2f1e-ede6-40c3-815b-b0090a8cfe3a.PNG)\n",
        "\n",
        "<br/>\n",
        "\n",
        "\n",
        "![Fig7-1-7](https://user-images.githubusercontent.com/44194558/142807488-e4325e58-b26f-4535-b57f-5f92b02d4619.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQowLGy1MTal"
      },
      "source": [
        "Resnet, Transformer같이 잔차 연결을 추가하는 경향도 존재\n",
        "- 하위 층의 출력 텐서를 상위 층의 출력 텐서에 더해 아래층의 representation이 소실되지 않고 네트워크의 위쪽으로 전달될 수 있게 함\n",
        "- 하위 층에서 학습한 정보의 손실 방지\n",
        "\n",
        "\n",
        "\n",
        "![Fig7-1-8](https://user-images.githubusercontent.com/44194558/142807753-1d806059-2adc-42fc-b513-e2a6ce5a5024.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBxtre-qNAx-"
      },
      "source": [
        "## Functional API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6z40irxNgKN"
      },
      "source": [
        "입력 텐서와 출력 텐서만 가지고 Model 객체를 생성\n",
        "- 케라스는 input_tensor에서 output_tensor로 가는 데 필요한 모든 층을 추출\n",
        "- 층들을 모아 그래프 데이터 구조인 Model 객체를 생성\n",
        "- 관련되지 않은 입력과 출력으로 모델을 생성하면 RuntimeError 발생\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci-UzeC1JKEP"
      },
      "source": [
        "from tensorflow.keras import Input, layers\n",
        "\n",
        "input_tensor = Input(shape=(32,))\n",
        "dense = layers.Dense(32, activation='relu')\n",
        "\n",
        "output_tensor = dense(input_tensor)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6s0ei7nNR3O",
        "outputId": "0f488a59-4e2a-495e-ba45-8a568de63794"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Input\n",
        "\n",
        "# Sequential\n",
        "seq_model = Sequential()\n",
        "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
        "seq_model.add(layers.Dense(32, activation='relu'))\n",
        "seq_model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Functional\n",
        "input_tensor = Input(shape=(64,))\n",
        "x = layers.Dense(32, activation='relu')(input_tensor)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(input_tensor, output_tensor)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 64)]              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 3,466\n",
            "Trainable params: 3,466\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "oGY9M3t-NGzx",
        "outputId": "dbd4fc19-2c8a-4454-e281-056bc233ade2"
      },
      "source": [
        "# Keras가 출력 텐서에서 input_3의 텐서로 접근할 수 없어 에러 발생\n",
        "unrelated_input = Input(shape=(32,))\n",
        "bad_model = model = Model(unrelated_input, output_tensor)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-54197a8d0ec3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0munrelated_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbad_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munrelated_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0;32m--> 198\u001b[0;31m         self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    987\u001b[0m                              \u001b[0;34m'The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m                              \u001b[0;34m'were accessed without issue: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m                              str(layers_with_complete_input))\n\u001b[0m\u001b[1;32m    990\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m           \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\") at layer \"dense_4\". The following previous layers were accessed without issue: []"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7G34AQbN2mF",
        "outputId": "64d609f6-e945-4986-cb62-80296207d516"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "\n",
        "x_train = np.random.random((1000, 64))\n",
        "y_train = np.random.random((1000, 10))\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=128)\n",
        "\n",
        "score = model.evaluate(x_train, y_train)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 2s 3ms/step - loss: 11.8970\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 12.8434\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 14.6306\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 17.4011\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 21.0335\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 25.2580\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 29.8442\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 34.8750\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 40.4258\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 46.5323\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 50.6004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZDbbu4YOaL0"
      },
      "source": [
        "## Multi-input models\n",
        "\n",
        "함수형 API는 다중 입력 모델을 만드는 데 사용 가능\n",
        "- 서로 다른 입력 branch를 합치기 위해 여러 텐서를 연결할 수 있는 층을 사용\n",
        "- 텐서를 더하거나 이어 붙이는 방식 (Element wise sum, concatenation)\n",
        "- keras.layers.add, keras.layers.concatenate 등 사용\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbH2_lkkOzsG"
      },
      "source": [
        "\n",
        "![Fig7-1-16](https://user-images.githubusercontent.com/44194558/142808493-caf3de1a-a8b1-41d1-a660-36adf7e2d222.PNG)\n",
        "\n",
        "<br/>\n",
        "\n",
        "질문-응답 모델은 2개의 입력을 가짐\n",
        "- 자연어 질문 + 답변에 필요한 정보가 담겨 있는 텍스트 (질문에 대한 답 출력)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5ImyzxfOUmS"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Input\n",
        "\n",
        "text_vocabulary_size = 10000\n",
        "question_vocabulary_size = 10000\n",
        "answer_vocabulary_size = 500\n",
        "\n",
        "# 텍스트\n",
        "text_input = Input(shape=(None, ), dtype='int32', name='text')  # 텍스트 입력 : 길이가 정해지지 않은 정수 시퀀스 / (None, None)\n",
        "embedded_text = layers.Embedding(64, text_vocabulary_size)(text_input)  # 크기가 64인 벡터의 시퀀스로 임베딩 / (None, None, 64)\n",
        "encoded_text = layers.LSTM(32)(embedded_text)  # 인코딩 / (None, 32)\n",
        "\n",
        "# 질문\n",
        "question_input = Input(shape=(None, ), dtype='int32', name='question')  # (None, None)\n",
        "embedded_question = layers.Embedding(32, question_vocabulary_size)(question_input)  # (None, None, 32)\n",
        "encoded_question = layers.LSTM(16)(embedded_question)  # (None, None, 16)\n",
        "\n",
        "# 합치기\n",
        "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)  # 인코딩된 질문, 텍스트를 연결, axis의 기본값은 -1 / (None, 32 + 16)\n",
        "\n",
        "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n",
        "\n",
        "model = Model([text_input, question_input], answer)  # 질문, 텍스트 2개의 입력을 받아 answer 출력\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSOO4Cr7Q2o-",
        "outputId": "e309b708-7b37-4c5b-d323-07e830ac4b14"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text (InputLayer)               [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "question (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 10000)  640000      text[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 10000)  320000      question[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 32)           1284224     embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 16)           641088      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 48)           0           lstm[0][0]                       \n",
            "                                                                 lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 500)          24500       concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 2,909,812\n",
            "Trainable params: 2,909,812\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7YSTHiFP5Ip",
        "outputId": "5649ccb5-f321-4d3f-ec3e-c3c4846e0c07"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "num_samples = 1000\n",
        "max_length = 100\n",
        "\n",
        "text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_length))\n",
        "question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_length))\n",
        "answers = np.random.randint(0, 1, size=(num_samples, answer_vocabulary_size))\n",
        "\n",
        "model.fit([text, question], answers, epochs=10, batch_size=128)\n",
        "\n",
        "model.fit({'text': text, 'question': question}, answers, epochs=10, batch_size=128)  # 입력의 이름을 설정해야 함"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 5s 100ms/step - loss: 0.0000e+00 - acc: 0.0630\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 1s 96ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 1/10\n",
            "8/8 [==============================] - 2s 97ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 1s 99ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 1s 97ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 1s 99ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 1s 98ms/step - loss: 0.0000e+00 - acc: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0f2663c650>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3aE83beRIC_",
        "outputId": "07bc319b-fdf1-43b6-b1e4-79fda6bcd6c1"
      },
      "source": [
        "print(text.shape)\n",
        "print(question.shape)\n",
        "print(answer.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 100)\n",
            "(1000, 100)\n",
            "(None, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPriIk4DQrTP"
      },
      "source": [
        "넘파이 배열의 리스트를 주입하거나 입력 이름과 넘파이 배열로 이루어진 딕셔너리를 모델의 입력으로 제공"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGmaQ0gARTRt"
      },
      "source": [
        "## Multi-output models\n",
        "\n",
        "데이터에 있는 여러 속성을 동시에 예측하는 네트워크\n",
        "- 소셜 미디어에서 사용자의 포스트를 입력받아 사용자의 나이, 성별, 소득 수준을 예측\n",
        "\n",
        "네트워크 출력 마다 다른 손실 함수를 지정해야 함\n",
        "- 손실들을 하나의 값으로 합쳐야 함\n",
        "- compile 메서드에 리스트/딕셔너리를 사용하여 출력마다 다른 손실을 지정할 수 있음\n",
        "- 계산된 손실값들은 전체 손실 하나로 합산되고, 훈련을 통해 최소화됨\n",
        "\n",
        "![Fig7-1-25](https://user-images.githubusercontent.com/44194558/142809447-b9aa0fd0-0979-455b-89ae-c68a4544cb5f.PNG)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfJLMm2PQv1q"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "vocabulary_size = 50000\n",
        "num_income_groups = 10\n",
        "\n",
        "posts_input = Input(shape=(None, ), dtype='int32', name='posts')\n",
        "embedded_posts = layers.Embedding(256, vocabulary_size)(posts_input)\n",
        "\n",
        "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
        "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "# 다중 출력\n",
        "age_prediction = layers.Dense(1, name='age')(x)\n",
        "income_prediction = layers.Dense(num_income_groups, activation='softmax', name='income')(x)\n",
        "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
        "\n",
        "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPw9e3vBR3Df",
        "outputId": "016f280b-2f75-4ee9-b89a-4cacbc3e1b4a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "posts (InputLayer)              [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 50000)  12800000    posts[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, None, 128)    32000128    embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, None, 128)    0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, None, 256)    164096      max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, None, 256)    327936      conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, None, 256)    0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, None, 256)    327936      max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, None, 256)    327936      conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d (GlobalMax (None, 256)          0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 128)          32896       global_max_pooling1d[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "age (Dense)                     (None, 1)            129         dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "income (Dense)                  (None, 10)           1290        dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gender (Dense)                  (None, 1)            129         dense_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 45,982,476\n",
            "Trainable params: 45,982,476\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CpR0W61R45L"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss={'age': 'mse',\n",
        "                                         'income': 'categorical_crossentropy',\n",
        "                                         'gender': 'binary_crossentropy'})"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inJpzKSgSm1U"
      },
      "source": [
        "손실값들의 불균형 정도가 크면 개별 손실이 가장 큰 작업에 치우쳐 최적화할 가능성이 높음 (다른 작업들이 손해를 보게 됨)\n",
        "\n",
        "- 개별 손실이 최종 손실에 기여하는 수준을 지정 가능 (손실값의 스케일이 다를 때 유효)\n",
        "- ex) 나이 regression의 MSE는 3~5, 성별 분류의 cross entropy는 0.1 정도일때 MSE 손실에 0.25의 가중치, cross entropy에 10의 가중치를 부여하여 균형을 맞춤"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Bj8CjWqSj4A"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
        "              loss_weights=[0.25, 1., 10.])\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss={'age': 'mse',\n",
        "                    'income': 'categorical_crossentropy',\n",
        "                    'gender': 'binary_crossentropy'},\n",
        "              loss_weights={'age': 0.25,\n",
        "                            'income': 1.,\n",
        "                            'gender': 10.})"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzSEsrC_ToMW"
      },
      "source": [
        "model.fit(posts, [age_targets, income_targets, gender_targets], epochs=10, batch_size=64)\n",
        "\n",
        "model.fit(posts, {'age': age_targets,\n",
        "                  'income': income_targets,\n",
        "                  'gender': gender_targets},\n",
        "          epochs=10, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7z1Fk_vTtmf"
      },
      "source": [
        "## Directed acyclic graphs of layers\n",
        "\n",
        "함수형 API를 사용하여 내부 토폴로지가 복잡한 네트워크를 생성\n",
        "- 비순환 = 원형 X (텐서 x가 자기 자신을 출력하는 층의 입력이 될 수 없음)\n",
        "- 만들 수 있는 루프는 순환 층의 내부에 있는 것 뿐\n",
        "\n",
        "인셉션 모듈과 잔차 연결이 가장 유명\n",
        "- 1x1 합성곱 (pointwise convolution)은 인셉션 모듈의 주요 특징 중 하나\n",
        "- 채널 방향의 특성 학습과 공간 방향의 특성 학습을 분리하는데 유용\n",
        "- 채널이 공간 방향으로 상관관계가 크고 채널 간에는 독립적일 때 유용 ex) Mobilenet, Xception"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNc-f0yIVCHK"
      },
      "source": [
        "![Fig7-1-37](https://user-images.githubusercontent.com/44194558/142810960-c0942392-0de4-4569-b549-00bc03e044de.PNG)"
      ]
    }
  ]
}